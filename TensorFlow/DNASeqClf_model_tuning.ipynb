{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on Splice-junction Gene Sequences \n",
    "This file takes the implemenation for hyperparameter search. \n",
    "Codes for hparam search and for tensorboard make it long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "MY_MODE_TRAINING = True\n",
    "MY_MODE_PREDICTION = False\n",
    "LOGDIR = './TMP/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_path) :\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    df.columns = ['classlabel', 'name', 'sequence']\n",
    "    df.tail()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the dataset\n",
    "* Apply one-hot-encoding to input data\n",
    "* Take 20% as test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df) :\n",
    "    \n",
    "    # Encoding class labels\n",
    "    class_le = LabelEncoder()\n",
    "    y = class_le.fit_transform(df['classlabel'].values)\n",
    "    #print(\"y:\",y)\n",
    "    \n",
    "    # Encoding sequence\n",
    "    # Here we use one hot encoding to encode the character in DNA sequence. \n",
    "    # So each dna sequence is converted to a 60x8 2D array \n",
    "    def Seq2Vec(seq):\n",
    "        s = str(seq).strip()\n",
    "        CharDict = { \"A\":[0,0,0,0,0,0,0,1],\n",
    "                     \"G\":[0,0,0,0,0,0,1,0],\n",
    "                     \"C\":[0,0,0,0,0,1,0,0],\n",
    "                     \"T\":[0,0,0,0,1,0,0,0],\n",
    "                     \"D\":[0,0,0,1,0,0,0,0],\n",
    "                     \"N\":[0,0,1,0,0,0,0,0],\n",
    "                     \"S\":[0,1,0,0,0,0,0,0],\n",
    "                     \"R\":[1,0,0,0,0,0,0,0]}\n",
    "        return np.asarray([CharDict[c] for c in s], dtype=np.float32).flatten()\n",
    "\n",
    "    df['seqvec'] = df['sequence'].apply(Seq2Vec)\n",
    "    X = np.vstack(df['seqvec'].values)\n",
    "    print(\"Total samples:\", X.shape[0])\n",
    "    \n",
    "    # Split the data set into training/test set\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    print(\"Training samples: \", X_train.shape[0], \"Test samples: \", X_test.shape[0])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_dnn(X_train, y_train, X_test, y_test, hparam, batch_size=100, n_epochs=2000, \n",
    "              use_two_conv=True, n_fc=3, mode_learning=0) :\n",
    "    \n",
    "    #DNN approach\n",
    "    '''\n",
    "    feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "    dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300, 100], n_classes=3,\n",
    "                                             feature_columns=feature_columns)\n",
    "    dnn_clf.fit(x=X_train, y=y_train, batch_size=50, steps=n_epochs)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    y_pred = list(dnn_clf.predict(X_test))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy\n",
    "    '''\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    " \n",
    "    # Hyper parameters\n",
    "    assert( n_fc>=1 & n_fc<=4 )\n",
    "    if( n_fc==4 ) : \n",
    "        fc1_node = 300\n",
    "        fc2_node = 100\n",
    "        fc3_node = 30\n",
    "    elif( n_fc==3 ) : \n",
    "        fc2_node = 300\n",
    "        fc3_node = 100\n",
    "    elif( n_fc==2 ) :\n",
    "        fc3_node = 200\n",
    "        \n",
    "    beta = 0.01                  # Regularization 0.01\n",
    "    dropout_rate = 0.5           # Dropout rate for dropout layer\n",
    "    learning_rate_set = [0.001, 1e-3, 1e-4, 1e-5]\n",
    "    assert( mode_learning>=0 & mode_learning<=3 )\n",
    "    starter_learning_rate = learning_rate_set[mode_learning]\n",
    "    \n",
    "    # Variables and inputs\n",
    "    X = tf.placeholder(tf.float32, shape=(None, 480), name=\"X\")\n",
    "    input = tf.reshape(X, [-1, 60*8])\n",
    "    y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "    mode = tf.placeholder(tf.bool, shape=(None), name=\"mode\")\n",
    "    scale = tf.placeholder(tf.float32, shape=(None), name=\"scale\")\n",
    "    global_step = tf.placeholder(tf.int32, shape=(None), name=\"global_step\")\n",
    "    learning_rate = tf.Variable(starter_learning_rate, trainable=False)\n",
    "    \n",
    "    if( n_fc == 4 ) :\n",
    "        # Add the 1st fully connected layer, apply L2 regularizer and xavier weight initializer\n",
    "        fc1 = tf.layers.dense(\n",
    "            inputs=input, \n",
    "            units=fc1_node, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"fc1\")\n",
    "\n",
    "        #Adding a dropout layer to avoid overfitting\n",
    "        dropout1 = tf.layers.dropout(inputs=fc1, rate=dropout_rate, training=mode )\n",
    "     \n",
    "    if( n_fc>=3 ) : \n",
    "        # Add the 2nd fully connected layer\n",
    "        fc2 = tf.layers.dense(\n",
    "            inputs= input if n_fc==3 else dropout1, \n",
    "            units=fc2_node, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"fc2\")\n",
    "    \n",
    "        #Adding a dropout layer to avoid overfitting\n",
    "        dropout2 = tf.layers.dropout(inputs=fc2, rate=dropout_rate, training=mode )\n",
    "    \n",
    "    if( n_fc>=2 ) : \n",
    "        # Add the 2nd fully connected layer\n",
    "        fc3 = tf.layers.dense(\n",
    "            inputs= input if n_fc==2 else dropout2, \n",
    "            units=fc3_node, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"fc3\")\n",
    "\n",
    "        #Adding a dropout layer to avoid overfitting\n",
    "        dropout3 = tf.layers.dropout(inputs=fc3, rate=dropout_rate, training=mode )\n",
    "    \n",
    "    # The last output layer\n",
    "    logits = tf.layers.dense(\n",
    "        inputs=input if n_fc==1 else dropout3, \n",
    "        units=3,\n",
    "        activation=tf.nn.softmax,\n",
    "        kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "        kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        name=\"output_FC\")\n",
    "    \n",
    "    # Cross entropy\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    \n",
    "    # Apply regularization in training stage and not in prediction stage\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(entropy) + beta*sum( tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES) )\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        if(mode_learning==0):\n",
    "            # Decayed learning rate\n",
    "            # Start learning rate as 0.001, decay rate as 0.5, decay 6 steps to ~0.000015 (~1e-5)\n",
    "            learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                       decay_steps=n_epochs//6, decay_rate=0.5, staircase=True)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        # Use Adam optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.nn.in_top_k(logits, y, 1)\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        train_writer = tf.summary.FileWriter(hparam + 'train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(hparam + \"test\")\n",
    "        \n",
    "        init.run()\n",
    "        n_rounds = X_train.shape[0] // batch_size\n",
    "        for epoch in range(n_epochs):\n",
    "            X_batch, y_batch = next_batch(batch_size, X_train, y_train, epoch, n_rounds)\n",
    "            summary_train, _ = sess.run([merged, optimizer], \n",
    "                                        feed_dict= {X: X_batch, y: y_batch, \n",
    "                                                    mode: MY_MODE_TRAINING, scale: beta,\n",
    "                                                    global_step: epoch}) \n",
    "            train_writer.add_summary(summary_train, epoch)\n",
    "\n",
    "            if (epoch % 10 == 0):\n",
    "                _, acc_train = sess.run([merged, accuracy], feed_dict={X: X_train, y: y_train, \n",
    "                                                    mode: MY_MODE_PREDICTION, scale: 0,\n",
    "                                                    global_step: epoch})\n",
    "                #train_writer.add_summary(summary_train, epoch)\n",
    "                \n",
    "                summary_test, acc_test = sess.run([merged, accuracy], \n",
    "                                                  feed_dict={X: X_test, y:y_test, \n",
    "                                                            mode: MY_MODE_PREDICTION, scale: 0,\n",
    "                                                            global_step: epoch})\n",
    "                test_writer.add_summary(summary_test, epoch)\n",
    "               \n",
    "                print(epoch, \"Train accuracy:\", acc_train,  \"Test_accuracy:\", acc_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next batch - support function\n",
    "* Get the next mini_batch from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels, epoch, rounds):\n",
    "    ''' \n",
    "    Return a total of `num` random samples and labels. \n",
    "    Reshuffle the index when running over the total data set epoch%rounds==0\n",
    "    \n",
    "    Arg: \n",
    "      num, the number of returned data size\n",
    "      data, the input X\n",
    "      labels, the label y\n",
    "      epoch, the current epoch value\n",
    "      rounds, rounds = label_size // num \n",
    "\n",
    "    Returns:\n",
    "      Return \"num\" of X and y array\n",
    "    '''\n",
    "    global g_idx\n",
    "    set_cnt = epoch % rounds\n",
    "    if( (set_cnt) == 0 ) :\n",
    "        #print(\"Reshuffling...\")\n",
    "        g_idx = np.arange(0, labels.shape[0])\n",
    "        np.random.shuffle(g_idx)\n",
    "        \n",
    "\n",
    "    idx = g_idx[set_cnt*num:set_cnt*num+num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_cnn(X_train, y_train, X_test, y_test, hparam, batch_size=100, n_epochs=2000, \n",
    "              use_two_conv=True, n_fc=3, mode_learning=0) :\n",
    "    \n",
    "    #CNN approach\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    #Hyper parameters\n",
    "    conv1_depth = 32\n",
    "    conv2_depth = 64\n",
    "    conv1_kernel_size = [3, 3]\n",
    "    conv2_kernel_size = [3, 3]\n",
    "    dense1_node = 64\n",
    "    dense2_node = 16\n",
    "    beta = 0.01                  # Regularization 0.01\n",
    "    dropout_rate = 0.5           # Dropout rate for dropout layer\n",
    "    learning_rate_set = [0.01, 1e-3, 1e-4, 1e-5]\n",
    "    assert( mode_learning>=0 & mode_learning<=3 )\n",
    "    starter_learning_rate = learning_rate_set[mode_learning]\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, 480), name=\"X\")\n",
    "    input = tf.reshape(X, [-1, 60, 8, 1])\n",
    "    y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "    mode = tf.placeholder(tf.bool, shape=(None), name=\"mode\")\n",
    "    scale = tf.placeholder(tf.float32, shape=(None), name=\"scale\")\n",
    "    global_step = tf.placeholder(tf.int32, shape=(None), name=\"global_step\")\n",
    "    learning_rate = tf.Variable(starter_learning_rate, trainable=False)\n",
    "    \n",
    "    if( use_two_conv ) :   # Use two conv layer\n",
    "        # Convolutional Layer #1\n",
    "        # Computes 32 features using a 3x3 filter.\n",
    "        # Padding is added to preserve width and height.\n",
    "        # Input Tensor Shape: [batch_size, 60, 8, 1]\n",
    "        # Output Tensor Shape: [batch_size, 60, 8, 32]\n",
    "        conv1 = tf.layers.conv2d(\n",
    "            inputs=input,\n",
    "            filters=conv1_depth,\n",
    "            kernel_size=conv1_kernel_size,\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "            name=\"conv1\")\n",
    "\n",
    "        #Adding a pooling layer\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        # Convolutional Layer #2\n",
    "        # Computes 64 features using a 3x3 filter.\n",
    "        # Padding is added to preserve width and height.\n",
    "        # Input Tensor Shape: [batch_size, 30, 4, 32]\n",
    "        # Output Tensor Shape: [batch_size, 30, 4, 64]\n",
    "        conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=conv2_depth,\n",
    "            kernel_size=conv2_kernel_size,\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "            name=\"conv2\")\n",
    "\n",
    "        #Adding a pooling layer\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "        conv_out_flat = tf.reshape(pool2, [-1, 15 * 2 * conv2_depth])\n",
    "        \n",
    "    else :   # Use one conv layer\n",
    "        conv2 = tf.layers.conv2d(\n",
    "            inputs=input,\n",
    "            filters=conv2_depth,\n",
    "            kernel_size=conv2_kernel_size,\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "            name=\"conv\")\n",
    "\n",
    "        #Adding a pooling layer\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "        conv_out_flat = tf.reshape(pool2, [-1, 30 * 4 * conv2_depth])\n",
    "        \n",
    "    if( n_fc==3 ) : # Use 3 FC layer\n",
    "        #Adding a fully connected layer\n",
    "        dense1 = tf.layers.dense(\n",
    "            inputs=conv_out_flat, \n",
    "            units=dense1_node, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"dense1\")\n",
    "\n",
    "        #Adding a dropout layer to avoid overfitting\n",
    "        dropout1 = tf.layers.dropout(inputs=dense1, rate=dropout_rate, training=mode )  \n",
    "\n",
    "        # Add the 2nd fully connected layer\n",
    "        dense2 = tf.layers.dense(\n",
    "            inputs=dropout1, \n",
    "            units=dense2_node, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"dense2\")\n",
    "\n",
    "        # The last output layer\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=dense2, \n",
    "            units=3,\n",
    "            activation=tf.nn.softmax,\n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"output_FC\")\n",
    "        \n",
    "    elif( n_fc==2 ) : # Use 2 FC layer\n",
    "        #Adding a fully connected layer\n",
    "        dense1 = tf.layers.dense(\n",
    "            inputs=conv_out_flat, \n",
    "            units=dense1_node, \n",
    "            activation=tf.nn.relu, \n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"dense1\")\n",
    "\n",
    "        #Adding a dropout layer to avoid overfitting\n",
    "        dropout1 = tf.layers.dropout(inputs=dense1, rate=dropout_rate, training=mode )  \n",
    "\n",
    "        # The last output layer\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=dropout1, \n",
    "            units=3,\n",
    "            activation=tf.nn.softmax,\n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"output_FC\")\n",
    "        \n",
    "    else : # Use 1 FC layer\n",
    "        # The last output layer\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=conv_out_flat, \n",
    "            units=3,\n",
    "            activation=tf.nn.softmax,\n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=scale, scope=None),\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            name=\"output_FC\")\n",
    "        \n",
    "    # Cross entropy\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    \n",
    "    # Apply regularization in training stage and not in prediction stage\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(entropy) + beta*sum( tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES) )\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        if(mode_learning==0):\n",
    "            # Decayed learning rate\n",
    "            # Start learning rate as 0.01, decay rate as 0.5, decay 10 steps to ~0.0000097 (~1e-5)\n",
    "            learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                       decay_steps=n_epochs//10, decay_rate=0.5, staircase=True)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        # Use Adam optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.nn.in_top_k(logits, y, 1)\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        train_writer = tf.summary.FileWriter(hparam + 'train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(hparam + \"test\")\n",
    "        \n",
    "        init.run()\n",
    "        n_rounds = X_train.shape[0] // batch_size\n",
    "        for epoch in range(n_epochs):\n",
    "            X_batch, y_batch = next_batch(batch_size, X_train, y_train, epoch, n_rounds)\n",
    "            summary_train, _ = sess.run([merged, optimizer], \n",
    "                                        feed_dict= {X: X_batch, y: y_batch, \n",
    "                                                    mode: MY_MODE_TRAINING, scale: beta,\n",
    "                                                    global_step: epoch}) \n",
    "            train_writer.add_summary(summary_train, epoch)\n",
    "\n",
    "            if (epoch % 10 == 0):\n",
    "                _, acc_train = sess.run([merged, accuracy], \n",
    "                                        feed_dict={X: X_train, y: y_train, \n",
    "                                                   mode: MY_MODE_PREDICTION, scale: 0,\n",
    "                                                   global_step: epoch})\n",
    "                #train_writer.add_summary(summary_train, epoch)\n",
    "                \n",
    "                summary_test, acc_test = sess.run([merged, accuracy], \n",
    "                                                  feed_dict={X: X_test, y:y_test, \n",
    "                                                            mode: MY_MODE_PREDICTION, scale: 0,\n",
    "                                                            global_step: epoch})\n",
    "                test_writer.add_summary(summary_test, epoch)\n",
    "               \n",
    "                print(epoch, \"Train accuracy:\", acc_train,  \"Test_accuracy:\", acc_test)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_rnn(X_train, y_train, X_test, y_test, hparam, batch_size=100, n_epochs=2000, \n",
    "              n_node=80, n_fc_node=64, mode_learning=0) :\n",
    "    \n",
    "    #RNN approach\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Input/output data dimension\n",
    "    n_steps =  60\n",
    "    n_inputs = 8\n",
    "    n_outputs = 3\n",
    "    \n",
    "    #Hyper parameters\n",
    "    n_neurons = n_node\n",
    "    fc1_node = n_fc_node\n",
    "    beta = 0.2                   # Regularization 0.2\n",
    "    dropout_rate = 0.5           # Dropout layer for regularization\n",
    "    learning_rate_set = [0.001, 1e-3, 1e-4, 1e-5]\n",
    "    assert( mode_learning>=0 & mode_learning<=3 )\n",
    "    starter_learning_rate = learning_rate_set[mode_learning]\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_steps * n_inputs), name=\"X\")\n",
    "    input = tf.reshape(X, [-1, n_steps, n_inputs])\n",
    "    y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "    mode = tf.placeholder(tf.bool, shape=(None), name=\"mode\")\n",
    "    scale = tf.placeholder(tf.float32, shape=(None), name=\"scale\")\n",
    "    global_step = tf.placeholder(tf.int32, shape=(None), name=\"global_step\")\n",
    "    learning_rate = tf.Variable(starter_learning_rate, trainable=False)\n",
    "    \n",
    "    # RNN layer\n",
    "    basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "    outputs, states = tf.nn.dynamic_rnn(basic_cell, input, dtype=tf.float32)\n",
    "        \n",
    "    # Dropout layer to avoid overfitting\n",
    "    dropout = tf.layers.dropout(inputs=states, rate=dropout_rate, training= mode )\n",
    "\n",
    "    if( n_fc_node>0 ) : # Try out two FC layers if fc_node is non-zero\n",
    "        # Fully connected layer - Xavier initializer and L2 regularizer\n",
    "        fc1 = tf.contrib.layers.fully_connected(\n",
    "            inputs=dropout, \n",
    "            num_outputs=fc1_node, \n",
    "            weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            weights_regularizer=tf.contrib.layers.l2_regularizer(scale=beta, scope=None),\n",
    "            activation_fn=tf.nn.relu \n",
    "        )\n",
    "        # Dropout layer to avoid overfitting\n",
    "        dropout2 = tf.layers.dropout(inputs=fc1, rate=dropout_rate, training= mode )\n",
    "\n",
    "    # Fully connected layer - Xavier initializer and L2 regularizer\n",
    "    logits = tf.contrib.layers.fully_connected(\n",
    "        inputs=dropout if n_fc_node==0 else dropout2,\n",
    "        num_outputs=n_outputs, \n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        weights_regularizer=tf.contrib.layers.l2_regularizer(scale=beta, scope=None),\n",
    "        #activation_fn=tf.nn.softmax \n",
    "    )\n",
    "\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    \n",
    "    # Apply regularization in training stage and not in prediction stage\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(entropy) + beta*sum( tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES) )\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        if(mode_learning==0):\n",
    "            # Decayed learning rate\n",
    "            # Start learning rate as 0.001, decay rate as 0.5, decay 6 steps to ~0.000015 (~1e-5)\n",
    "            learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                                       decay_steps=n_epochs//6, decay_rate=0.5, staircase=True)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        # Use Adam optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct_prediction = tf.nn.in_top_k(logits, y, 1)\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        train_writer = tf.summary.FileWriter(hparam + 'train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(hparam + \"test\")\n",
    "        \n",
    "        init.run()\n",
    "        n_rounds = X_train.shape[0] // batch_size\n",
    "        for epoch in range(n_epochs):\n",
    "            X_batch, y_batch = next_batch(batch_size, X_train, y_train, epoch, n_rounds)\n",
    "            summary_train, _ = sess.run([merged, optimizer], \n",
    "                                        feed_dict= {X: X_batch, y: y_batch, \n",
    "                                                    mode: MY_MODE_TRAINING, scale: beta,\n",
    "                                                    global_step: epoch}) \n",
    "            train_writer.add_summary(summary_train, epoch)\n",
    "\n",
    "            if (epoch % 10 == 0):\n",
    "                _, acc_train = sess.run([merged, accuracy], \n",
    "                                        feed_dict={X: X_train, y: y_train, \n",
    "                                                   mode: MY_MODE_PREDICTION, scale: 0,\n",
    "                                                   global_step: epoch})\n",
    "                #train_writer.add_summary(summary_train, epoch)\n",
    "                \n",
    "                summary_test, acc_test = sess.run([merged, accuracy], \n",
    "                                                  feed_dict={X: X_test, y:y_test, \n",
    "                                                            mode: MY_MODE_PREDICTION, scale: 0,\n",
    "                                                            global_step: epoch})\n",
    "                test_writer.add_summary(summary_test, epoch)\n",
    "               \n",
    "                print(epoch, \"Train accuracy:\", acc_train,  \"Test_accuracy:\", acc_test)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_hparam_string(model_name, mode_learning, n_fc, n_conv):\n",
    "    conv_param = \"conv=%d\" % (n_conv)\n",
    "    return LOGDIR+model_name+\",lr_%d,%s,fc=%d,\" % (mode_learning, conv_param, n_fc)\n",
    "\n",
    "def main(unused_argv):\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data(\"..\\data\\splice.data\")\n",
    "    \n",
    "    # Preprocess data and split training and validation data\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(df)\n",
    "    \n",
    "    # DNN model\n",
    "    '''\n",
    "    for mode_learning in [0, 1, 2, 3]:\n",
    "        for n_fc in [4, 3, 2, 1]:\n",
    "            hparam = make_hparam_string(\"dnn\", mode_learning=mode_learning, n_fc=n_fc, n_conv=0)\n",
    "            print('Starting run for %s' % hparam)\n",
    "            \n",
    "            model_dnn(X_train, y_train, X_test, y_test, hparam=hparam, batch_size=100, n_epochs=5000, \n",
    "                      n_fc=n_fc, mode_learning=mode_learning)\n",
    "    '''\n",
    "        \n",
    "    # CNN model\n",
    "    '''\n",
    "    # Search hyper parameters over the different # of layers\n",
    "    for n_fc in [3, 2, 1]:\n",
    "        for n_conv in [2, 1]:\n",
    "            # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2)\n",
    "            hparam = make_hparam_string(\"cnn_1\", 2, n_fc, n_conv=n_conv)\n",
    "\n",
    "            print('Starting run for %s' % hparam)\n",
    "            model_cnn(X_train, y_train, X_test, y_test, batch_size=100, n_epochs=3000, hparam=hparam,\n",
    "                      use_two_conv=(n_conv==2), n_fc=n_fc, mode_learning=2)\n",
    "    '''\n",
    "    '''\n",
    "    # Search and compare the best learning rate\n",
    "    for mode_learning in [0, 1, 2, 3]:\n",
    "        n_fc=3\n",
    "        for two_conv in [1]:\n",
    "            # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2)\n",
    "            hparam = make_hparam_string(\"cnn_2\", mode_learning=mode_learning, n_fc=n_fc, n_conv=n_conv)\n",
    "\n",
    "            print('Starting run for %s' % hparam)\n",
    "            model_cnn(X_train, y_train, X_test, y_test, batch_size=100, n_epochs=3000, hparam=hparam,\n",
    "                      use_two_conv=(n_conv==2), n_fc=n_fc, mode_learning=mode_learning)\n",
    "    '''\n",
    "    \n",
    "    # RNN model\n",
    "    #model_rnn(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, batch_size=100, n_epochs=3000)\n",
    "    for mode_learning in [1]:\n",
    "        for n_node in [32, 64, 80, 150]:\n",
    "            for n_fc_node in [0]:\n",
    "                hparam = LOGDIR+\"rnn,lr_%d,rnn_node=%d,fc_node=%d,\" % (mode_learning, n_node, n_fc_node)\n",
    "                print('Starting run for %s' % hparam)\n",
    "\n",
    "                model_rnn(X_train, y_train, X_test, y_test, hparam=hparam, batch_size=100, n_epochs=3000, \n",
    "                          n_node=n_node, n_fc_node=n_fc_node, mode_learning=mode_learning)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3190\n",
      "Training samples:  2552 Test samples:  638\n",
      "Starting run for ./TMP/rnn,lr_1,rnn_node=32,fc_node=0,\n",
      "0 Train accuracy: 0.402821 Test_accuracy: 0.376176\n",
      "10 Train accuracy: 0.622257 Test_accuracy: 0.598746\n",
      "20 Train accuracy: 0.695141 Test_accuracy: 0.675549\n",
      "30 Train accuracy: 0.548589 Test_accuracy: 0.545455\n",
      "40 Train accuracy: 0.518809 Test_accuracy: 0.518809\n",
      "50 Train accuracy: 0.520768 Test_accuracy: 0.520376\n",
      "60 Train accuracy: 0.538009 Test_accuracy: 0.539185\n",
      "70 Train accuracy: 0.520768 Test_accuracy: 0.520376\n",
      "80 Train accuracy: 0.586991 Test_accuracy: 0.581505\n",
      "90 Train accuracy: 0.545455 Test_accuracy: 0.53605\n",
      "100 Train accuracy: 0.538401 Test_accuracy: 0.528213\n",
      "110 Train accuracy: 0.622257 Test_accuracy: 0.611285\n",
      "120 Train accuracy: 0.523511 Test_accuracy: 0.521944\n",
      "130 Train accuracy: 0.570141 Test_accuracy: 0.568965\n",
      "140 Train accuracy: 0.534875 Test_accuracy: 0.525078\n",
      "150 Train accuracy: 0.593652 Test_accuracy: 0.590909\n",
      "160 Train accuracy: 0.538009 Test_accuracy: 0.526646\n",
      "170 Train accuracy: 0.586599 Test_accuracy: 0.584639\n",
      "180 Train accuracy: 0.534875 Test_accuracy: 0.526646\n",
      "190 Train accuracy: 0.591301 Test_accuracy: 0.587774\n",
      "200 Train accuracy: 0.554075 Test_accuracy: 0.545455\n",
      "210 Train accuracy: 0.552116 Test_accuracy: 0.54232\n",
      "220 Train accuracy: 0.560737 Test_accuracy: 0.553292\n",
      "230 Train accuracy: 0.543103 Test_accuracy: 0.532915\n",
      "240 Train accuracy: 0.560737 Test_accuracy: 0.557994\n",
      "250 Train accuracy: 0.572884 Test_accuracy: 0.570533\n",
      "260 Train accuracy: 0.567006 Test_accuracy: 0.557994\n",
      "270 Train accuracy: 0.557602 Test_accuracy: 0.5721\n",
      "280 Train accuracy: 0.547022 Test_accuracy: 0.547022\n",
      "290 Train accuracy: 0.544279 Test_accuracy: 0.531348\n",
      "300 Train accuracy: 0.547806 Test_accuracy: 0.543887\n",
      "310 Train accuracy: 0.547414 Test_accuracy: 0.554859\n",
      "320 Train accuracy: 0.549765 Test_accuracy: 0.561128\n",
      "330 Train accuracy: 0.55094 Test_accuracy: 0.53605\n",
      "340 Train accuracy: 0.532132 Test_accuracy: 0.548589\n",
      "350 Train accuracy: 0.553683 Test_accuracy: 0.554859\n",
      "360 Train accuracy: 0.550157 Test_accuracy: 0.557994\n",
      "370 Train accuracy: 0.559561 Test_accuracy: 0.557994\n",
      "380 Train accuracy: 0.51058 Test_accuracy: 0.509404\n",
      "390 Train accuracy: 0.561912 Test_accuracy: 0.570533\n",
      "400 Train accuracy: 0.555251 Test_accuracy: 0.562696\n",
      "410 Train accuracy: 0.547414 Test_accuracy: 0.53605\n",
      "420 Train accuracy: 0.561128 Test_accuracy: 0.550157\n",
      "430 Train accuracy: 0.546238 Test_accuracy: 0.525078\n",
      "440 Train accuracy: 0.558777 Test_accuracy: 0.54232\n",
      "450 Train accuracy: 0.556426 Test_accuracy: 0.550157\n",
      "460 Train accuracy: 0.561912 Test_accuracy: 0.53605\n",
      "470 Train accuracy: 0.562696 Test_accuracy: 0.561128\n",
      "480 Train accuracy: 0.556426 Test_accuracy: 0.531348\n",
      "490 Train accuracy: 0.563088 Test_accuracy: 0.559561\n",
      "500 Train accuracy: 0.560737 Test_accuracy: 0.570533\n",
      "510 Train accuracy: 0.558777 Test_accuracy: 0.540752\n",
      "520 Train accuracy: 0.547022 Test_accuracy: 0.543887\n",
      "530 Train accuracy: 0.575235 Test_accuracy: 0.573668\n",
      "540 Train accuracy: 0.572492 Test_accuracy: 0.570533\n",
      "550 Train accuracy: 0.567006 Test_accuracy: 0.557994\n",
      "560 Train accuracy: 0.548589 Test_accuracy: 0.528213\n",
      "570 Train accuracy: 0.577978 Test_accuracy: 0.54232\n",
      "580 Train accuracy: 0.559169 Test_accuracy: 0.557994\n",
      "590 Train accuracy: 0.580721 Test_accuracy: 0.548589\n",
      "600 Train accuracy: 0.586599 Test_accuracy: 0.5721\n",
      "610 Train accuracy: 0.576802 Test_accuracy: 0.537618\n",
      "620 Train accuracy: 0.593652 Test_accuracy: 0.547022\n",
      "630 Train accuracy: 0.594044 Test_accuracy: 0.551724\n",
      "640 Train accuracy: 0.60815 Test_accuracy: 0.568965\n",
      "650 Train accuracy: 0.594436 Test_accuracy: 0.54232\n",
      "660 Train accuracy: 0.579154 Test_accuracy: 0.561128\n",
      "670 Train accuracy: 0.568574 Test_accuracy: 0.562696\n",
      "680 Train accuracy: 0.48511 Test_accuracy: 0.496865\n",
      "690 Train accuracy: 0.603056 Test_accuracy: 0.570533\n",
      "700 Train accuracy: 0.569749 Test_accuracy: 0.540752\n",
      "710 Train accuracy: 0.652821 Test_accuracy: 0.589342\n",
      "720 Train accuracy: 0.628135 Test_accuracy: 0.598746\n",
      "730 Train accuracy: 0.664969 Test_accuracy: 0.617555\n",
      "740 Train accuracy: 0.670846 Test_accuracy: 0.612853\n",
      "750 Train accuracy: 0.668495 Test_accuracy: 0.619122\n",
      "760 Train accuracy: 0.711207 Test_accuracy: 0.659875\n",
      "770 Train accuracy: 0.712774 Test_accuracy: 0.678683\n",
      "780 Train accuracy: 0.725705 Test_accuracy: 0.678683\n",
      "790 Train accuracy: 0.708856 Test_accuracy: 0.655172\n",
      "800 Train accuracy: 0.635972 Test_accuracy: 0.611285\n",
      "810 Train accuracy: 0.64185 Test_accuracy: 0.617555\n",
      "820 Train accuracy: 0.681426 Test_accuracy: 0.65047\n",
      "830 Train accuracy: 0.732759 Test_accuracy: 0.69906\n",
      "840 Train accuracy: 0.729232 Test_accuracy: 0.702194\n",
      "850 Train accuracy: 0.737853 Test_accuracy: 0.714734\n",
      "860 Train accuracy: 0.721787 Test_accuracy: 0.700627\n",
      "870 Train accuracy: 0.75 Test_accuracy: 0.725705\n",
      "880 Train accuracy: 0.746082 Test_accuracy: 0.727273\n",
      "890 Train accuracy: 0.706505 Test_accuracy: 0.694357\n",
      "900 Train accuracy: 0.736677 Test_accuracy: 0.705329\n",
      "910 Train accuracy: 0.741771 Test_accuracy: 0.69279\n",
      "920 Train accuracy: 0.722179 Test_accuracy: 0.683386\n",
      "930 Train accuracy: 0.701411 Test_accuracy: 0.681818\n",
      "940 Train accuracy: 0.74373 Test_accuracy: 0.716301\n",
      "950 Train accuracy: 0.730408 Test_accuracy: 0.69906\n",
      "960 Train accuracy: 0.670063 Test_accuracy: 0.617555\n",
      "970 Train accuracy: 0.750784 Test_accuracy: 0.716301\n",
      "980 Train accuracy: 0.755878 Test_accuracy: 0.724138\n",
      "990 Train accuracy: 0.762147 Test_accuracy: 0.727273\n",
      "1000 Train accuracy: 0.770376 Test_accuracy: 0.73511\n",
      "1010 Train accuracy: 0.708856 Test_accuracy: 0.683386\n",
      "1020 Train accuracy: 0.689263 Test_accuracy: 0.630094\n",
      "1030 Train accuracy: 0.758621 Test_accuracy: 0.719436\n",
      "1040 Train accuracy: 0.777821 Test_accuracy: 0.739812\n",
      "1050 Train accuracy: 0.786442 Test_accuracy: 0.744514\n",
      "1060 Train accuracy: 0.734326 Test_accuracy: 0.694357\n",
      "1070 Train accuracy: 0.754702 Test_accuracy: 0.72884\n",
      "1080 Train accuracy: 0.722962 Test_accuracy: 0.714734\n",
      "1090 Train accuracy: 0.76489 Test_accuracy: 0.719436\n",
      "1100 Train accuracy: 0.701802 Test_accuracy: 0.658307\n",
      "1110 Train accuracy: 0.697492 Test_accuracy: 0.664577\n",
      "1120 Train accuracy: 0.746082 Test_accuracy: 0.719436\n",
      "1130 Train accuracy: 0.726489 Test_accuracy: 0.677116\n",
      "1140 Train accuracy: 0.772335 Test_accuracy: 0.731975\n",
      "1150 Train accuracy: 0.753135 Test_accuracy: 0.721003\n",
      "1160 Train accuracy: 0.780956 Test_accuracy: 0.73511\n",
      "1170 Train accuracy: 0.755486 Test_accuracy: 0.714734\n",
      "1180 Train accuracy: 0.759404 Test_accuracy: 0.721003\n",
      "1190 Train accuracy: 0.748041 Test_accuracy: 0.702194\n",
      "1200 Train accuracy: 0.79232 Test_accuracy: 0.746082\n",
      "1210 Train accuracy: 0.784483 Test_accuracy: 0.730408\n",
      "1220 Train accuracy: 0.755878 Test_accuracy: 0.708464\n",
      "1230 Train accuracy: 0.775078 Test_accuracy: 0.739812\n",
      "1240 Train accuracy: 0.760972 Test_accuracy: 0.714734\n",
      "1250 Train accuracy: 0.79663 Test_accuracy: 0.755486\n",
      "1260 Train accuracy: 0.798589 Test_accuracy: 0.753918\n",
      "1270 Train accuracy: 0.789185 Test_accuracy: 0.736677\n",
      "1280 Train accuracy: 0.760188 Test_accuracy: 0.727273\n",
      "1290 Train accuracy: 0.785658 Test_accuracy: 0.744514\n",
      "1300 Train accuracy: 0.741771 Test_accuracy: 0.713166\n",
      "1310 Train accuracy: 0.799765 Test_accuracy: 0.742947\n",
      "1320 Train accuracy: 0.768809 Test_accuracy: 0.721003\n",
      "1330 Train accuracy: 0.804859 Test_accuracy: 0.747649\n",
      "1340 Train accuracy: 0.767241 Test_accuracy: 0.725705\n",
      "1350 Train accuracy: 0.762147 Test_accuracy: 0.710031\n",
      "1360 Train accuracy: 0.795063 Test_accuracy: 0.761755\n",
      "1370 Train accuracy: 0.706897 Test_accuracy: 0.672414\n",
      "1380 Train accuracy: 0.779389 Test_accuracy: 0.741379\n",
      "1390 Train accuracy: 0.809953 Test_accuracy: 0.758621\n",
      "1400 Train accuracy: 0.782132 Test_accuracy: 0.738245\n",
      "1410 Train accuracy: 0.760972 Test_accuracy: 0.713166\n",
      "1420 Train accuracy: 0.770768 Test_accuracy: 0.72884\n",
      "1430 Train accuracy: 0.769984 Test_accuracy: 0.739812\n",
      "1440 Train accuracy: 0.791536 Test_accuracy: 0.739812\n",
      "1450 Train accuracy: 0.759796 Test_accuracy: 0.72884\n",
      "1460 Train accuracy: 0.784875 Test_accuracy: 0.752351\n",
      "1470 Train accuracy: 0.786834 Test_accuracy: 0.742947\n",
      "1480 Train accuracy: 0.807994 Test_accuracy: 0.747649\n",
      "1490 Train accuracy: 0.81348 Test_accuracy: 0.785266\n",
      "1500 Train accuracy: 0.782132 Test_accuracy: 0.721003\n",
      "1510 Train accuracy: 0.8029 Test_accuracy: 0.758621\n",
      "1520 Train accuracy: 0.797414 Test_accuracy: 0.733542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530 Train accuracy: 0.809561 Test_accuracy: 0.761755\n",
      "1540 Train accuracy: 0.783699 Test_accuracy: 0.72884\n",
      "1550 Train accuracy: 0.81348 Test_accuracy: 0.763323\n",
      "1560 Train accuracy: 0.817006 Test_accuracy: 0.778997\n",
      "1570 Train accuracy: 0.746082 Test_accuracy: 0.703762\n",
      "1580 Train accuracy: 0.799373 Test_accuracy: 0.744514\n",
      "1590 Train accuracy: 0.748433 Test_accuracy: 0.725705\n",
      "1600 Train accuracy: 0.753527 Test_accuracy: 0.717868\n",
      "1610 Train accuracy: 0.777429 Test_accuracy: 0.730408\n",
      "1620 Train accuracy: 0.826019 Test_accuracy: 0.766458\n",
      "1630 Train accuracy: 0.824451 Test_accuracy: 0.766458\n",
      "1640 Train accuracy: 0.802508 Test_accuracy: 0.757053\n",
      "1650 Train accuracy: 0.81779 Test_accuracy: 0.755486\n",
      "1660 Train accuracy: 0.827586 Test_accuracy: 0.774295\n",
      "1670 Train accuracy: 0.821708 Test_accuracy: 0.786834\n",
      "1680 Train accuracy: 0.709639 Test_accuracy: 0.697492\n",
      "1690 Train accuracy: 0.747649 Test_accuracy: 0.702194\n",
      "1700 Train accuracy: 0.799373 Test_accuracy: 0.760188\n",
      "1710 Train accuracy: 0.793103 Test_accuracy: 0.72884\n",
      "1720 Train accuracy: 0.812304 Test_accuracy: 0.769592\n",
      "1730 Train accuracy: 0.797022 Test_accuracy: 0.747649\n",
      "1740 Train accuracy: 0.816223 Test_accuracy: 0.758621\n",
      "1750 Train accuracy: 0.8029 Test_accuracy: 0.755486\n",
      "1760 Train accuracy: 0.818574 Test_accuracy: 0.758621\n",
      "1770 Train accuracy: 0.81152 Test_accuracy: 0.749216\n",
      "1780 Train accuracy: 0.815047 Test_accuracy: 0.757053\n",
      "1790 Train accuracy: 0.840909 Test_accuracy: 0.774295\n",
      "1800 Train accuracy: 0.791536 Test_accuracy: 0.738245\n",
      "1810 Train accuracy: 0.810345 Test_accuracy: 0.775862\n",
      "1820 Train accuracy: 0.837774 Test_accuracy: 0.794671\n",
      "1830 Train accuracy: 0.827586 Test_accuracy: 0.775862\n",
      "1840 Train accuracy: 0.787226 Test_accuracy: 0.738245\n",
      "1850 Train accuracy: 0.818182 Test_accuracy: 0.777429\n",
      "1860 Train accuracy: 0.800157 Test_accuracy: 0.730408\n",
      "1870 Train accuracy: 0.83268 Test_accuracy: 0.780564\n",
      "1880 Train accuracy: 0.81779 Test_accuracy: 0.783699\n",
      "1890 Train accuracy: 0.834639 Test_accuracy: 0.772727\n",
      "1900 Train accuracy: 0.824451 Test_accuracy: 0.778997\n",
      "1910 Train accuracy: 0.823276 Test_accuracy: 0.778997\n",
      "1920 Train accuracy: 0.817006 Test_accuracy: 0.755486\n",
      "1930 Train accuracy: 0.793495 Test_accuracy: 0.739812\n",
      "1940 Train accuracy: 0.811912 Test_accuracy: 0.769592\n",
      "1950 Train accuracy: 0.827194 Test_accuracy: 0.775862\n",
      "1960 Train accuracy: 0.841693 Test_accuracy: 0.783699\n",
      "1970 Train accuracy: 0.800549 Test_accuracy: 0.757053\n",
      "1980 Train accuracy: 0.777429 Test_accuracy: 0.741379\n",
      "1990 Train accuracy: 0.809561 Test_accuracy: 0.763323\n",
      "2000 Train accuracy: 0.803683 Test_accuracy: 0.750784\n",
      "2010 Train accuracy: 0.802508 Test_accuracy: 0.750784\n",
      "2020 Train accuracy: 0.8221 Test_accuracy: 0.793103\n",
      "2030 Train accuracy: 0.830721 Test_accuracy: 0.810345\n",
      "2040 Train accuracy: 0.755878 Test_accuracy: 0.727273\n",
      "2050 Train accuracy: 0.805643 Test_accuracy: 0.76489\n",
      "2060 Train accuracy: 0.83268 Test_accuracy: 0.786834\n",
      "2070 Train accuracy: 0.815047 Test_accuracy: 0.769592\n",
      "2080 Train accuracy: 0.839342 Test_accuracy: 0.80721\n",
      "2090 Train accuracy: 0.832288 Test_accuracy: 0.788401\n",
      "2100 Train accuracy: 0.847962 Test_accuracy: 0.80721\n",
      "2110 Train accuracy: 0.827194 Test_accuracy: 0.775862\n",
      "2120 Train accuracy: 0.84326 Test_accuracy: 0.789969\n",
      "2130 Train accuracy: 0.846787 Test_accuracy: 0.797806\n",
      "2140 Train accuracy: 0.84953 Test_accuracy: 0.80094\n",
      "2150 Train accuracy: 0.844828 Test_accuracy: 0.791536\n",
      "2160 Train accuracy: 0.850705 Test_accuracy: 0.810345\n",
      "2170 Train accuracy: 0.816223 Test_accuracy: 0.783699\n",
      "2180 Train accuracy: 0.739028 Test_accuracy: 0.69279\n",
      "2190 Train accuracy: 0.756661 Test_accuracy: 0.714734\n",
      "2200 Train accuracy: 0.784091 Test_accuracy: 0.744514\n",
      "2210 Train accuracy: 0.829937 Test_accuracy: 0.793103\n",
      "2220 Train accuracy: 0.83895 Test_accuracy: 0.797806\n",
      "2230 Train accuracy: 0.842085 Test_accuracy: 0.791536\n",
      "2240 Train accuracy: 0.846787 Test_accuracy: 0.799373\n",
      "2250 Train accuracy: 0.836599 Test_accuracy: 0.80721\n",
      "2260 Train accuracy: 0.85384 Test_accuracy: 0.808777\n",
      "2270 Train accuracy: 0.834639 Test_accuracy: 0.791536\n",
      "2280 Train accuracy: 0.813088 Test_accuracy: 0.750784\n",
      "2290 Train accuracy: 0.827194 Test_accuracy: 0.789969\n",
      "2300 Train accuracy: 0.833072 Test_accuracy: 0.799373\n",
      "2310 Train accuracy: 0.806035 Test_accuracy: 0.757053\n",
      "2320 Train accuracy: 0.841301 Test_accuracy: 0.786834\n",
      "2330 Train accuracy: 0.841693 Test_accuracy: 0.786834\n",
      "2340 Train accuracy: 0.855016 Test_accuracy: 0.810345\n",
      "2350 Train accuracy: 0.824843 Test_accuracy: 0.782132\n",
      "2360 Train accuracy: 0.846395 Test_accuracy: 0.804075\n",
      "2370 Train accuracy: 0.846395 Test_accuracy: 0.815047\n",
      "2380 Train accuracy: 0.855408 Test_accuracy: 0.805643\n",
      "2390 Train accuracy: 0.859326 Test_accuracy: 0.80721\n",
      "2400 Train accuracy: 0.837382 Test_accuracy: 0.797806\n",
      "2410 Train accuracy: 0.797414 Test_accuracy: 0.742947\n",
      "2420 Train accuracy: 0.818574 Test_accuracy: 0.76489\n",
      "2430 Train accuracy: 0.77116 Test_accuracy: 0.721003\n",
      "2440 Train accuracy: 0.844436 Test_accuracy: 0.80094\n",
      "2450 Train accuracy: 0.856191 Test_accuracy: 0.815047\n",
      "2460 Train accuracy: 0.851881 Test_accuracy: 0.80094\n",
      "2470 Train accuracy: 0.864028 Test_accuracy: 0.811912\n",
      "2480 Train accuracy: 0.834248 Test_accuracy: 0.780564\n",
      "2490 Train accuracy: 0.824451 Test_accuracy: 0.782132\n",
      "2500 Train accuracy: 0.837382 Test_accuracy: 0.782132\n",
      "2510 Train accuracy: 0.836991 Test_accuracy: 0.780564\n",
      "2520 Train accuracy: 0.863245 Test_accuracy: 0.818182\n",
      "2530 Train accuracy: 0.857759 Test_accuracy: 0.811912\n",
      "2540 Train accuracy: 0.87069 Test_accuracy: 0.826019\n",
      "2550 Train accuracy: 0.855016 Test_accuracy: 0.80094\n",
      "2560 Train accuracy: 0.845219 Test_accuracy: 0.782132\n",
      "2570 Train accuracy: 0.847179 Test_accuracy: 0.796238\n",
      "2580 Train accuracy: 0.786442 Test_accuracy: 0.736677\n",
      "2590 Train accuracy: 0.815439 Test_accuracy: 0.786834\n",
      "2600 Train accuracy: 0.857367 Test_accuracy: 0.827586\n",
      "2610 Train accuracy: 0.851881 Test_accuracy: 0.799373\n",
      "2620 Train accuracy: 0.858542 Test_accuracy: 0.824451\n",
      "2630 Train accuracy: 0.763323 Test_accuracy: 0.713166\n",
      "2640 Train accuracy: 0.779389 Test_accuracy: 0.738245\n",
      "2650 Train accuracy: 0.780956 Test_accuracy: 0.736677\n",
      "2660 Train accuracy: 0.806035 Test_accuracy: 0.785266\n",
      "2670 Train accuracy: 0.800549 Test_accuracy: 0.747649\n",
      "2680 Train accuracy: 0.828762 Test_accuracy: 0.786834\n",
      "2690 Train accuracy: 0.827586 Test_accuracy: 0.760188\n",
      "2700 Train accuracy: 0.818965 Test_accuracy: 0.777429\n",
      "2710 Train accuracy: 0.808777 Test_accuracy: 0.77116\n",
      "2720 Train accuracy: 0.836991 Test_accuracy: 0.789969\n",
      "2730 Train accuracy: 0.832288 Test_accuracy: 0.786834\n",
      "2740 Train accuracy: 0.853056 Test_accuracy: 0.805643\n",
      "2750 Train accuracy: 0.845219 Test_accuracy: 0.802508\n",
      "2760 Train accuracy: 0.865204 Test_accuracy: 0.830721\n",
      "2770 Train accuracy: 0.813872 Test_accuracy: 0.758621\n",
      "2780 Train accuracy: 0.847571 Test_accuracy: 0.794671\n",
      "2790 Train accuracy: 0.855799 Test_accuracy: 0.804075\n",
      "2800 Train accuracy: 0.855799 Test_accuracy: 0.822884\n",
      "2810 Train accuracy: 0.849138 Test_accuracy: 0.794671\n",
      "2820 Train accuracy: 0.842085 Test_accuracy: 0.808777\n",
      "2830 Train accuracy: 0.846003 Test_accuracy: 0.818182\n",
      "2840 Train accuracy: 0.847571 Test_accuracy: 0.80094\n",
      "2850 Train accuracy: 0.866379 Test_accuracy: 0.821317\n",
      "2860 Train accuracy: 0.800549 Test_accuracy: 0.742947\n",
      "2870 Train accuracy: 0.841301 Test_accuracy: 0.794671\n",
      "2880 Train accuracy: 0.859718 Test_accuracy: 0.802508\n",
      "2890 Train accuracy: 0.872257 Test_accuracy: 0.826019\n",
      "2900 Train accuracy: 0.81779 Test_accuracy: 0.777429\n",
      "2910 Train accuracy: 0.823276 Test_accuracy: 0.785266\n",
      "2920 Train accuracy: 0.867163 Test_accuracy: 0.818182\n",
      "2930 Train accuracy: 0.819357 Test_accuracy: 0.775862\n",
      "2940 Train accuracy: 0.824843 Test_accuracy: 0.782132\n",
      "2950 Train accuracy: 0.690047 Test_accuracy: 0.681818\n",
      "2960 Train accuracy: 0.814655 Test_accuracy: 0.761755\n",
      "2970 Train accuracy: 0.846003 Test_accuracy: 0.80094\n",
      "2980 Train accuracy: 0.860893 Test_accuracy: 0.81348\n",
      "2990 Train accuracy: 0.842476 Test_accuracy: 0.802508\n",
      "Starting run for ./TMP/rnn,lr_1,rnn_node=64,fc_node=0,\n",
      "0 Train accuracy: 0.371865 Test_accuracy: 0.390282\n",
      "10 Train accuracy: 0.520768 Test_accuracy: 0.514107\n",
      "20 Train accuracy: 0.523903 Test_accuracy: 0.518809\n",
      "30 Train accuracy: 0.585815 Test_accuracy: 0.575235\n",
      "40 Train accuracy: 0.545063 Test_accuracy: 0.534483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train accuracy: 0.588558 Test_accuracy: 0.597179\n",
      "60 Train accuracy: 0.630094 Test_accuracy: 0.611285\n",
      "70 Train accuracy: 0.633229 Test_accuracy: 0.617555\n",
      "80 Train accuracy: 0.611677 Test_accuracy: 0.600313\n",
      "90 Train accuracy: 0.572492 Test_accuracy: 0.576802\n",
      "100 Train accuracy: 0.601881 Test_accuracy: 0.601881\n",
      "110 Train accuracy: 0.619906 Test_accuracy: 0.637931\n",
      "120 Train accuracy: 0.649687 Test_accuracy: 0.642633\n",
      "130 Train accuracy: 0.626176 Test_accuracy: 0.61442\n",
      "140 Train accuracy: 0.64185 Test_accuracy: 0.65047\n",
      "150 Train accuracy: 0.644201 Test_accuracy: 0.631661\n",
      "160 Train accuracy: 0.653605 Test_accuracy: 0.655172\n",
      "170 Train accuracy: 0.634013 Test_accuracy: 0.615987\n",
      "180 Train accuracy: 0.664577 Test_accuracy: 0.667712\n",
      "190 Train accuracy: 0.669279 Test_accuracy: 0.666144\n",
      "200 Train accuracy: 0.668103 Test_accuracy: 0.670846\n",
      "210 Train accuracy: 0.612069 Test_accuracy: 0.598746\n",
      "220 Train accuracy: 0.612461 Test_accuracy: 0.631661\n",
      "230 Train accuracy: 0.628918 Test_accuracy: 0.628527\n",
      "240 Train accuracy: 0.647335 Test_accuracy: 0.658307\n",
      "250 Train accuracy: 0.653605 Test_accuracy: 0.644201\n",
      "260 Train accuracy: 0.653605 Test_accuracy: 0.663009\n",
      "270 Train accuracy: 0.624608 Test_accuracy: 0.619122\n",
      "280 Train accuracy: 0.694357 Test_accuracy: 0.691223\n",
      "290 Train accuracy: 0.736677 Test_accuracy: 0.713166\n",
      "300 Train accuracy: 0.779781 Test_accuracy: 0.755486\n",
      "310 Train accuracy: 0.796238 Test_accuracy: 0.774295\n",
      "320 Train accuracy: 0.798589 Test_accuracy: 0.780564\n",
      "330 Train accuracy: 0.811912 Test_accuracy: 0.810345\n",
      "340 Train accuracy: 0.839734 Test_accuracy: 0.821317\n",
      "350 Train accuracy: 0.873041 Test_accuracy: 0.847962\n",
      "360 Train accuracy: 0.880094 Test_accuracy: 0.852665\n",
      "370 Train accuracy: 0.887931 Test_accuracy: 0.851097\n",
      "380 Train accuracy: 0.83895 Test_accuracy: 0.835423\n",
      "390 Train accuracy: 0.752743 Test_accuracy: 0.747649\n",
      "400 Train accuracy: 0.764498 Test_accuracy: 0.758621\n",
      "410 Train accuracy: 0.880878 Test_accuracy: 0.855799\n",
      "420 Train accuracy: 0.88558 Test_accuracy: 0.865204\n",
      "430 Train accuracy: 0.904389 Test_accuracy: 0.896552\n",
      "440 Train accuracy: 0.900078 Test_accuracy: 0.874608\n",
      "450 Train accuracy: 0.910658 Test_accuracy: 0.918495\n",
      "460 Train accuracy: 0.907915 Test_accuracy: 0.905956\n",
      "470 Train accuracy: 0.905564 Test_accuracy: 0.894984\n",
      "480 Train accuracy: 0.929075 Test_accuracy: 0.912226\n",
      "490 Train accuracy: 0.937304 Test_accuracy: 0.9279\n",
      "500 Train accuracy: 0.930643 Test_accuracy: 0.920063\n",
      "510 Train accuracy: 0.943965 Test_accuracy: 0.931035\n",
      "520 Train accuracy: 0.910658 Test_accuracy: 0.896552\n",
      "530 Train accuracy: 0.915752 Test_accuracy: 0.909091\n",
      "540 Train accuracy: 0.931035 Test_accuracy: 0.924765\n",
      "550 Train accuracy: 0.946317 Test_accuracy: 0.931035\n",
      "560 Train accuracy: 0.949843 Test_accuracy: 0.945141\n",
      "570 Train accuracy: 0.958464 Test_accuracy: 0.942006\n",
      "580 Train accuracy: 0.95337 Test_accuracy: 0.931035\n",
      "590 Train accuracy: 0.961207 Test_accuracy: 0.937304\n",
      "600 Train accuracy: 0.965517 Test_accuracy: 0.951411\n",
      "610 Train accuracy: 0.950235 Test_accuracy: 0.929467\n",
      "620 Train accuracy: 0.963558 Test_accuracy: 0.952978\n",
      "630 Train accuracy: 0.959248 Test_accuracy: 0.952978\n",
      "640 Train accuracy: 0.966693 Test_accuracy: 0.948276\n",
      "650 Train accuracy: 0.95768 Test_accuracy: 0.942006\n",
      "660 Train accuracy: 0.960423 Test_accuracy: 0.942006\n",
      "670 Train accuracy: 0.963558 Test_accuracy: 0.932602\n",
      "680 Train accuracy: 0.966693 Test_accuracy: 0.948276\n",
      "690 Train accuracy: 0.943574 Test_accuracy: 0.929467\n",
      "700 Train accuracy: 0.969828 Test_accuracy: 0.951411\n",
      "710 Train accuracy: 0.969044 Test_accuracy: 0.951411\n",
      "720 Train accuracy: 0.970219 Test_accuracy: 0.951411\n",
      "730 Train accuracy: 0.970611 Test_accuracy: 0.952978\n",
      "740 Train accuracy: 0.950235 Test_accuracy: 0.932602\n",
      "750 Train accuracy: 0.963558 Test_accuracy: 0.940439\n",
      "760 Train accuracy: 0.937304 Test_accuracy: 0.909091\n",
      "770 Train accuracy: 0.958856 Test_accuracy: 0.938872\n",
      "780 Train accuracy: 0.958072 Test_accuracy: 0.938872\n",
      "790 Train accuracy: 0.965517 Test_accuracy: 0.952978\n",
      "800 Train accuracy: 0.935345 Test_accuracy: 0.923198\n",
      "810 Train accuracy: 0.925549 Test_accuracy: 0.910658\n",
      "820 Train accuracy: 0.959639 Test_accuracy: 0.948276\n",
      "830 Train accuracy: 0.969436 Test_accuracy: 0.954545\n",
      "840 Train accuracy: 0.970611 Test_accuracy: 0.952978\n",
      "850 Train accuracy: 0.96395 Test_accuracy: 0.935737\n",
      "860 Train accuracy: 0.960423 Test_accuracy: 0.940439\n",
      "870 Train accuracy: 0.974922 Test_accuracy: 0.95768\n",
      "880 Train accuracy: 0.974138 Test_accuracy: 0.95768\n",
      "890 Train accuracy: 0.974922 Test_accuracy: 0.960815\n",
      "900 Train accuracy: 0.971395 Test_accuracy: 0.959248\n",
      "910 Train accuracy: 0.967868 Test_accuracy: 0.960815\n",
      "920 Train accuracy: 0.967085 Test_accuracy: 0.940439\n",
      "930 Train accuracy: 0.973354 Test_accuracy: 0.962382\n",
      "940 Train accuracy: 0.97884 Test_accuracy: 0.960815\n",
      "950 Train accuracy: 0.974138 Test_accuracy: 0.95768\n",
      "960 Train accuracy: 0.967868 Test_accuracy: 0.946708\n",
      "970 Train accuracy: 0.976881 Test_accuracy: 0.962382\n",
      "980 Train accuracy: 0.972571 Test_accuracy: 0.959248\n",
      "990 Train accuracy: 0.940831 Test_accuracy: 0.945141\n",
      "1000 Train accuracy: 0.975313 Test_accuracy: 0.959248\n",
      "1010 Train accuracy: 0.969044 Test_accuracy: 0.946708\n",
      "1020 Train accuracy: 0.969828 Test_accuracy: 0.949843\n",
      "1030 Train accuracy: 0.971003 Test_accuracy: 0.949843\n",
      "1040 Train accuracy: 0.971003 Test_accuracy: 0.951411\n",
      "1050 Train accuracy: 0.971787 Test_accuracy: 0.951411\n",
      "1060 Train accuracy: 0.964734 Test_accuracy: 0.952978\n",
      "1070 Train accuracy: 0.969044 Test_accuracy: 0.943574\n",
      "1080 Train accuracy: 0.975313 Test_accuracy: 0.954545\n",
      "1090 Train accuracy: 0.964734 Test_accuracy: 0.938872\n",
      "1100 Train accuracy: 0.951019 Test_accuracy: 0.935737\n",
      "1110 Train accuracy: 0.954545 Test_accuracy: 0.938872\n",
      "1120 Train accuracy: 0.971787 Test_accuracy: 0.948276\n",
      "1130 Train accuracy: 0.976097 Test_accuracy: 0.952978\n",
      "1140 Train accuracy: 0.970611 Test_accuracy: 0.960815\n",
      "1150 Train accuracy: 0.971395 Test_accuracy: 0.960815\n",
      "1160 Train accuracy: 0.981191 Test_accuracy: 0.962382\n",
      "1170 Train accuracy: 0.977665 Test_accuracy: 0.956113\n",
      "1180 Train accuracy: 0.974922 Test_accuracy: 0.95768\n",
      "1190 Train accuracy: 0.975313 Test_accuracy: 0.962382\n",
      "1200 Train accuracy: 0.974138 Test_accuracy: 0.96395\n",
      "1210 Train accuracy: 0.973354 Test_accuracy: 0.954545\n",
      "1220 Train accuracy: 0.977665 Test_accuracy: 0.967085\n",
      "1230 Train accuracy: 0.970611 Test_accuracy: 0.942006\n",
      "1240 Train accuracy: 0.973354 Test_accuracy: 0.960815\n",
      "1250 Train accuracy: 0.975705 Test_accuracy: 0.956113\n",
      "1260 Train accuracy: 0.959248 Test_accuracy: 0.937304\n",
      "1270 Train accuracy: 0.980016 Test_accuracy: 0.946708\n",
      "1280 Train accuracy: 0.971787 Test_accuracy: 0.956113\n",
      "1290 Train accuracy: 0.951019 Test_accuracy: 0.940439\n",
      "1300 Train accuracy: 0.948276 Test_accuracy: 0.942006\n",
      "1310 Train accuracy: 0.965125 Test_accuracy: 0.946708\n",
      "1320 Train accuracy: 0.939655 Test_accuracy: 0.920063\n",
      "1330 Train accuracy: 0.961599 Test_accuracy: 0.942006\n",
      "1340 Train accuracy: 0.969828 Test_accuracy: 0.945141\n",
      "1350 Train accuracy: 0.970611 Test_accuracy: 0.948276\n",
      "1360 Train accuracy: 0.964342 Test_accuracy: 0.942006\n",
      "1370 Train accuracy: 0.969044 Test_accuracy: 0.943574\n",
      "1380 Train accuracy: 0.97884 Test_accuracy: 0.962382\n",
      "1390 Train accuracy: 0.97884 Test_accuracy: 0.96395\n",
      "1400 Train accuracy: 0.979232 Test_accuracy: 0.96395\n",
      "1410 Train accuracy: 0.980408 Test_accuracy: 0.962382\n",
      "1420 Train accuracy: 0.981191 Test_accuracy: 0.96395\n",
      "1430 Train accuracy: 0.980799 Test_accuracy: 0.959248\n",
      "1440 Train accuracy: 0.980408 Test_accuracy: 0.959248\n",
      "1450 Train accuracy: 0.980799 Test_accuracy: 0.959248\n",
      "1460 Train accuracy: 0.969436 Test_accuracy: 0.949843\n",
      "1470 Train accuracy: 0.973746 Test_accuracy: 0.954545\n",
      "1480 Train accuracy: 0.980016 Test_accuracy: 0.96395\n",
      "1490 Train accuracy: 0.980408 Test_accuracy: 0.967085\n",
      "1500 Train accuracy: 0.980799 Test_accuracy: 0.968652\n",
      "1510 Train accuracy: 0.972571 Test_accuracy: 0.954545\n",
      "1520 Train accuracy: 0.979232 Test_accuracy: 0.967085\n",
      "1530 Train accuracy: 0.980799 Test_accuracy: 0.965517\n",
      "1540 Train accuracy: 0.980799 Test_accuracy: 0.956113\n",
      "1550 Train accuracy: 0.976097 Test_accuracy: 0.954545\n",
      "1560 Train accuracy: 0.972962 Test_accuracy: 0.943574\n",
      "1570 Train accuracy: 0.982759 Test_accuracy: 0.956113\n",
      "1580 Train accuracy: 0.97884 Test_accuracy: 0.960815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590 Train accuracy: 0.982759 Test_accuracy: 0.967085\n",
      "1600 Train accuracy: 0.981975 Test_accuracy: 0.968652\n",
      "1610 Train accuracy: 0.980408 Test_accuracy: 0.960815\n",
      "1620 Train accuracy: 0.979624 Test_accuracy: 0.95768\n",
      "1630 Train accuracy: 0.975313 Test_accuracy: 0.956113\n",
      "1640 Train accuracy: 0.978448 Test_accuracy: 0.95768\n",
      "1650 Train accuracy: 0.979232 Test_accuracy: 0.95768\n",
      "1660 Train accuracy: 0.974138 Test_accuracy: 0.949843\n",
      "1670 Train accuracy: 0.965125 Test_accuracy: 0.938872\n",
      "1680 Train accuracy: 0.977273 Test_accuracy: 0.954545\n",
      "1690 Train accuracy: 0.967085 Test_accuracy: 0.938872\n",
      "1700 Train accuracy: 0.963166 Test_accuracy: 0.940439\n",
      "1710 Train accuracy: 0.976881 Test_accuracy: 0.954545\n",
      "1720 Train accuracy: 0.979232 Test_accuracy: 0.959248\n",
      "1730 Train accuracy: 0.979624 Test_accuracy: 0.954545\n",
      "1740 Train accuracy: 0.978448 Test_accuracy: 0.949843\n",
      "1750 Train accuracy: 0.973354 Test_accuracy: 0.937304\n",
      "1760 Train accuracy: 0.958464 Test_accuracy: 0.926332\n",
      "1770 Train accuracy: 0.982367 Test_accuracy: 0.962382\n",
      "1780 Train accuracy: 0.975705 Test_accuracy: 0.960815\n",
      "1790 Train accuracy: 0.978448 Test_accuracy: 0.954545\n",
      "1800 Train accuracy: 0.982759 Test_accuracy: 0.959248\n",
      "1810 Train accuracy: 0.981191 Test_accuracy: 0.967085\n",
      "1820 Train accuracy: 0.982759 Test_accuracy: 0.965517\n",
      "1830 Train accuracy: 0.98315 Test_accuracy: 0.965517\n",
      "1840 Train accuracy: 0.986285 Test_accuracy: 0.960815\n",
      "1850 Train accuracy: 0.987069 Test_accuracy: 0.965517\n",
      "1860 Train accuracy: 0.976881 Test_accuracy: 0.951411\n",
      "1870 Train accuracy: 0.98511 Test_accuracy: 0.96395\n",
      "1880 Train accuracy: 0.981583 Test_accuracy: 0.95768\n",
      "1890 Train accuracy: 0.965517 Test_accuracy: 0.948276\n",
      "1900 Train accuracy: 0.944749 Test_accuracy: 0.929467\n",
      "1910 Train accuracy: 0.946317 Test_accuracy: 0.923198\n",
      "1920 Train accuracy: 0.969436 Test_accuracy: 0.945141\n",
      "1930 Train accuracy: 0.979624 Test_accuracy: 0.95768\n",
      "1940 Train accuracy: 0.982759 Test_accuracy: 0.96395\n",
      "1950 Train accuracy: 0.98511 Test_accuracy: 0.956113\n",
      "1960 Train accuracy: 0.977665 Test_accuracy: 0.952978\n",
      "1970 Train accuracy: 0.982759 Test_accuracy: 0.949843\n",
      "1980 Train accuracy: 0.980408 Test_accuracy: 0.952978\n",
      "1990 Train accuracy: 0.977273 Test_accuracy: 0.954545\n",
      "2000 Train accuracy: 0.987069 Test_accuracy: 0.965517\n",
      "2010 Train accuracy: 0.979624 Test_accuracy: 0.956113\n",
      "2020 Train accuracy: 0.973746 Test_accuracy: 0.942006\n",
      "2030 Train accuracy: 0.986285 Test_accuracy: 0.965517\n",
      "2040 Train accuracy: 0.987461 Test_accuracy: 0.954545\n",
      "2050 Train accuracy: 0.976489 Test_accuracy: 0.942006\n",
      "2060 Train accuracy: 0.979232 Test_accuracy: 0.951411\n",
      "2070 Train accuracy: 0.975313 Test_accuracy: 0.940439\n",
      "2080 Train accuracy: 0.987069 Test_accuracy: 0.954545\n",
      "2090 Train accuracy: 0.973746 Test_accuracy: 0.942006\n",
      "2100 Train accuracy: 0.981975 Test_accuracy: 0.951411\n",
      "2110 Train accuracy: 0.978448 Test_accuracy: 0.946708\n",
      "2120 Train accuracy: 0.985502 Test_accuracy: 0.954545\n",
      "2130 Train accuracy: 0.980408 Test_accuracy: 0.948276\n",
      "2140 Train accuracy: 0.982759 Test_accuracy: 0.95768\n",
      "2150 Train accuracy: 0.93652 Test_accuracy: 0.893417\n",
      "2160 Train accuracy: 0.963558 Test_accuracy: 0.943574\n",
      "2170 Train accuracy: 0.981191 Test_accuracy: 0.95768\n",
      "2180 Train accuracy: 0.983934 Test_accuracy: 0.956113\n",
      "2190 Train accuracy: 0.975705 Test_accuracy: 0.946708\n",
      "2200 Train accuracy: 0.981191 Test_accuracy: 0.949843\n",
      "2210 Train accuracy: 0.975313 Test_accuracy: 0.943574\n",
      "2220 Train accuracy: 0.986677 Test_accuracy: 0.954545\n",
      "2230 Train accuracy: 0.989028 Test_accuracy: 0.960815\n",
      "2240 Train accuracy: 0.989028 Test_accuracy: 0.960815\n",
      "2250 Train accuracy: 0.98315 Test_accuracy: 0.956113\n",
      "2260 Train accuracy: 0.98511 Test_accuracy: 0.940439\n",
      "2270 Train accuracy: 0.981583 Test_accuracy: 0.951411\n",
      "2280 Train accuracy: 0.984718 Test_accuracy: 0.951411\n",
      "2290 Train accuracy: 0.987461 Test_accuracy: 0.954545\n",
      "2300 Train accuracy: 0.98942 Test_accuracy: 0.95768\n",
      "2310 Train accuracy: 0.987853 Test_accuracy: 0.949843\n",
      "2320 Train accuracy: 0.988245 Test_accuracy: 0.96395\n",
      "2330 Train accuracy: 0.986285 Test_accuracy: 0.954545\n",
      "2340 Train accuracy: 0.97453 Test_accuracy: 0.949843\n",
      "2350 Train accuracy: 0.979624 Test_accuracy: 0.954545\n",
      "2360 Train accuracy: 0.985893 Test_accuracy: 0.95768\n",
      "2370 Train accuracy: 0.980799 Test_accuracy: 0.951411\n",
      "2380 Train accuracy: 0.992555 Test_accuracy: 0.967085\n",
      "2390 Train accuracy: 0.980408 Test_accuracy: 0.945141\n",
      "2400 Train accuracy: 0.991379 Test_accuracy: 0.962382\n",
      "2410 Train accuracy: 0.990204 Test_accuracy: 0.956113\n",
      "2420 Train accuracy: 0.989812 Test_accuracy: 0.96395\n",
      "2430 Train accuracy: 0.991379 Test_accuracy: 0.956113\n",
      "2440 Train accuracy: 0.991771 Test_accuracy: 0.967085\n",
      "2450 Train accuracy: 0.991379 Test_accuracy: 0.956113\n",
      "2460 Train accuracy: 0.989028 Test_accuracy: 0.954545\n",
      "2470 Train accuracy: 0.986285 Test_accuracy: 0.959248\n",
      "2480 Train accuracy: 0.98942 Test_accuracy: 0.960815\n",
      "2490 Train accuracy: 0.992555 Test_accuracy: 0.956113\n",
      "2500 Train accuracy: 0.992555 Test_accuracy: 0.962382\n",
      "2510 Train accuracy: 0.991379 Test_accuracy: 0.952978\n",
      "2520 Train accuracy: 0.991379 Test_accuracy: 0.960815\n",
      "2530 Train accuracy: 0.983542 Test_accuracy: 0.952978\n",
      "2540 Train accuracy: 0.971395 Test_accuracy: 0.952978\n",
      "2550 Train accuracy: 0.981191 Test_accuracy: 0.952978\n",
      "2560 Train accuracy: 0.98942 Test_accuracy: 0.95768\n",
      "2570 Train accuracy: 0.982367 Test_accuracy: 0.965517\n",
      "2580 Train accuracy: 0.988245 Test_accuracy: 0.956113\n",
      "2590 Train accuracy: 0.984718 Test_accuracy: 0.951411\n",
      "2600 Train accuracy: 0.990987 Test_accuracy: 0.962382\n",
      "2610 Train accuracy: 0.992947 Test_accuracy: 0.956113\n",
      "2620 Train accuracy: 0.983934 Test_accuracy: 0.948276\n",
      "2630 Train accuracy: 0.976881 Test_accuracy: 0.9279\n",
      "2640 Train accuracy: 0.976881 Test_accuracy: 0.940439\n",
      "2650 Train accuracy: 0.990596 Test_accuracy: 0.962382\n",
      "2660 Train accuracy: 0.990987 Test_accuracy: 0.954545\n",
      "2670 Train accuracy: 0.991379 Test_accuracy: 0.956113\n",
      "2680 Train accuracy: 0.990204 Test_accuracy: 0.95768\n",
      "2690 Train accuracy: 0.969828 Test_accuracy: 0.934169\n",
      "2700 Train accuracy: 0.985502 Test_accuracy: 0.948276\n",
      "2710 Train accuracy: 0.977665 Test_accuracy: 0.945141\n",
      "2720 Train accuracy: 0.989028 Test_accuracy: 0.959248\n",
      "2730 Train accuracy: 0.974922 Test_accuracy: 0.951411\n",
      "2740 Train accuracy: 0.98315 Test_accuracy: 0.954545\n",
      "2750 Train accuracy: 0.972571 Test_accuracy: 0.954545\n",
      "2760 Train accuracy: 0.991379 Test_accuracy: 0.956113\n",
      "2770 Train accuracy: 0.98942 Test_accuracy: 0.952978\n",
      "2780 Train accuracy: 0.988636 Test_accuracy: 0.960815\n",
      "2790 Train accuracy: 0.992555 Test_accuracy: 0.954545\n",
      "2800 Train accuracy: 0.993339 Test_accuracy: 0.959248\n",
      "2810 Train accuracy: 0.991379 Test_accuracy: 0.962382\n",
      "2820 Train accuracy: 0.973354 Test_accuracy: 0.934169\n",
      "2830 Train accuracy: 0.985893 Test_accuracy: 0.945141\n",
      "2840 Train accuracy: 0.981191 Test_accuracy: 0.946708\n",
      "2850 Train accuracy: 0.98315 Test_accuracy: 0.960815\n",
      "2860 Train accuracy: 0.988245 Test_accuracy: 0.949843\n",
      "2870 Train accuracy: 0.991771 Test_accuracy: 0.956113\n",
      "2880 Train accuracy: 0.990204 Test_accuracy: 0.952978\n",
      "2890 Train accuracy: 0.987069 Test_accuracy: 0.946708\n",
      "2900 Train accuracy: 0.96826 Test_accuracy: 0.935737\n",
      "2910 Train accuracy: 0.992555 Test_accuracy: 0.954545\n",
      "2920 Train accuracy: 0.98942 Test_accuracy: 0.956113\n",
      "2930 Train accuracy: 0.984326 Test_accuracy: 0.952978\n",
      "2940 Train accuracy: 0.968652 Test_accuracy: 0.932602\n",
      "2950 Train accuracy: 0.983542 Test_accuracy: 0.946708\n",
      "2960 Train accuracy: 0.981583 Test_accuracy: 0.949843\n",
      "2970 Train accuracy: 0.991379 Test_accuracy: 0.954545\n",
      "2980 Train accuracy: 0.992163 Test_accuracy: 0.95768\n",
      "2990 Train accuracy: 0.994514 Test_accuracy: 0.959248\n",
      "Starting run for ./TMP/rnn,lr_1,rnn_node=80,fc_node=0,\n",
      "0 Train accuracy: 0.481583 Test_accuracy: 0.495298\n",
      "10 Train accuracy: 0.518809 Test_accuracy: 0.518809\n",
      "20 Train accuracy: 0.562304 Test_accuracy: 0.553292\n",
      "30 Train accuracy: 0.543103 Test_accuracy: 0.539185\n",
      "40 Train accuracy: 0.721003 Test_accuracy: 0.691223\n",
      "50 Train accuracy: 0.604232 Test_accuracy: 0.605016\n",
      "60 Train accuracy: 0.621473 Test_accuracy: 0.622257\n",
      "70 Train accuracy: 0.610893 Test_accuracy: 0.600313\n",
      "80 Train accuracy: 0.598746 Test_accuracy: 0.592476\n",
      "90 Train accuracy: 0.636755 Test_accuracy: 0.625392\n",
      "100 Train accuracy: 0.636755 Test_accuracy: 0.612853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 Train accuracy: 0.642241 Test_accuracy: 0.628527\n",
      "120 Train accuracy: 0.644592 Test_accuracy: 0.65047\n",
      "130 Train accuracy: 0.661834 Test_accuracy: 0.639498\n",
      "140 Train accuracy: 0.690831 Test_accuracy: 0.667712\n",
      "150 Train accuracy: 0.702978 Test_accuracy: 0.691223\n",
      "160 Train accuracy: 0.716301 Test_accuracy: 0.684953\n",
      "170 Train accuracy: 0.75 Test_accuracy: 0.72884\n",
      "180 Train accuracy: 0.679467 Test_accuracy: 0.669279\n",
      "190 Train accuracy: 0.787226 Test_accuracy: 0.750784\n",
      "200 Train accuracy: 0.768809 Test_accuracy: 0.753918\n",
      "210 Train accuracy: 0.826019 Test_accuracy: 0.796238\n",
      "220 Train accuracy: 0.769984 Test_accuracy: 0.736677\n",
      "230 Train accuracy: 0.833856 Test_accuracy: 0.791536\n",
      "240 Train accuracy: 0.83268 Test_accuracy: 0.782132\n",
      "250 Train accuracy: 0.86442 Test_accuracy: 0.804075\n",
      "260 Train accuracy: 0.873433 Test_accuracy: 0.821317\n",
      "270 Train accuracy: 0.89185 Test_accuracy: 0.841693\n",
      "280 Train accuracy: 0.850313 Test_accuracy: 0.811912\n",
      "290 Train accuracy: 0.881661 Test_accuracy: 0.824451\n",
      "300 Train accuracy: 0.840909 Test_accuracy: 0.789969\n",
      "310 Train accuracy: 0.849138 Test_accuracy: 0.810345\n",
      "320 Train accuracy: 0.902038 Test_accuracy: 0.847962\n",
      "330 Train accuracy: 0.894592 Test_accuracy: 0.84326\n",
      "340 Train accuracy: 0.888715 Test_accuracy: 0.840125\n",
      "350 Train accuracy: 0.87931 Test_accuracy: 0.830721\n",
      "360 Train accuracy: 0.876567 Test_accuracy: 0.865204\n",
      "370 Train accuracy: 0.909483 Test_accuracy: 0.873041\n",
      "380 Train accuracy: 0.900862 Test_accuracy: 0.871473\n",
      "390 Train accuracy: 0.793495 Test_accuracy: 0.775862\n",
      "400 Train accuracy: 0.853056 Test_accuracy: 0.818182\n",
      "410 Train accuracy: 0.882837 Test_accuracy: 0.84326\n",
      "420 Train accuracy: 0.929075 Test_accuracy: 0.88558\n",
      "430 Train accuracy: 0.922022 Test_accuracy: 0.888715\n",
      "440 Train accuracy: 0.907524 Test_accuracy: 0.858934\n",
      "450 Train accuracy: 0.932994 Test_accuracy: 0.898119\n",
      "460 Train accuracy: 0.930643 Test_accuracy: 0.893417\n",
      "470 Train accuracy: 0.92163 Test_accuracy: 0.860502\n",
      "480 Train accuracy: 0.907915 Test_accuracy: 0.866771\n",
      "490 Train accuracy: 0.909875 Test_accuracy: 0.847962\n",
      "500 Train accuracy: 0.924373 Test_accuracy: 0.89185\n",
      "510 Train accuracy: 0.927508 Test_accuracy: 0.912226\n",
      "520 Train accuracy: 0.931818 Test_accuracy: 0.89185\n",
      "530 Train accuracy: 0.939655 Test_accuracy: 0.898119\n",
      "540 Train accuracy: 0.923589 Test_accuracy: 0.896552\n",
      "550 Train accuracy: 0.883229 Test_accuracy: 0.857367\n",
      "560 Train accuracy: 0.935737 Test_accuracy: 0.92163\n",
      "570 Train accuracy: 0.907524 Test_accuracy: 0.898119\n",
      "580 Train accuracy: 0.924765 Test_accuracy: 0.874608\n",
      "590 Train accuracy: 0.920063 Test_accuracy: 0.894984\n",
      "600 Train accuracy: 0.923198 Test_accuracy: 0.890282\n",
      "610 Train accuracy: 0.931426 Test_accuracy: 0.904389\n",
      "620 Train accuracy: 0.946317 Test_accuracy: 0.916928\n",
      "630 Train accuracy: 0.951411 Test_accuracy: 0.920063\n",
      "640 Train accuracy: 0.917712 Test_accuracy: 0.893417\n",
      "650 Train accuracy: 0.941614 Test_accuracy: 0.920063\n",
      "660 Train accuracy: 0.951411 Test_accuracy: 0.931035\n",
      "670 Train accuracy: 0.938872 Test_accuracy: 0.909091\n",
      "680 Train accuracy: 0.952586 Test_accuracy: 0.92163\n",
      "690 Train accuracy: 0.952586 Test_accuracy: 0.92163\n",
      "700 Train accuracy: 0.950235 Test_accuracy: 0.92163\n",
      "710 Train accuracy: 0.94906 Test_accuracy: 0.942006\n",
      "720 Train accuracy: 0.951019 Test_accuracy: 0.937304\n",
      "730 Train accuracy: 0.959639 Test_accuracy: 0.934169\n",
      "740 Train accuracy: 0.960815 Test_accuracy: 0.943574\n",
      "750 Train accuracy: 0.947492 Test_accuracy: 0.929467\n",
      "760 Train accuracy: 0.961991 Test_accuracy: 0.940439\n",
      "770 Train accuracy: 0.960031 Test_accuracy: 0.940439\n",
      "780 Train accuracy: 0.941614 Test_accuracy: 0.912226\n",
      "790 Train accuracy: 0.964342 Test_accuracy: 0.938872\n",
      "800 Train accuracy: 0.952978 Test_accuracy: 0.910658\n",
      "810 Train accuracy: 0.93221 Test_accuracy: 0.890282\n",
      "820 Train accuracy: 0.964734 Test_accuracy: 0.9279\n",
      "830 Train accuracy: 0.96395 Test_accuracy: 0.938872\n",
      "840 Train accuracy: 0.966693 Test_accuracy: 0.940439\n",
      "850 Train accuracy: 0.963558 Test_accuracy: 0.932602\n",
      "860 Train accuracy: 0.968652 Test_accuracy: 0.937304\n",
      "870 Train accuracy: 0.965909 Test_accuracy: 0.949843\n",
      "880 Train accuracy: 0.971395 Test_accuracy: 0.951411\n",
      "890 Train accuracy: 0.971395 Test_accuracy: 0.945141\n",
      "900 Train accuracy: 0.964342 Test_accuracy: 0.945141\n",
      "910 Train accuracy: 0.965517 Test_accuracy: 0.935737\n",
      "920 Train accuracy: 0.971395 Test_accuracy: 0.949843\n",
      "930 Train accuracy: 0.970611 Test_accuracy: 0.949843\n",
      "940 Train accuracy: 0.974922 Test_accuracy: 0.949843\n",
      "950 Train accuracy: 0.971787 Test_accuracy: 0.943574\n",
      "960 Train accuracy: 0.973746 Test_accuracy: 0.948276\n",
      "970 Train accuracy: 0.972179 Test_accuracy: 0.932602\n",
      "980 Train accuracy: 0.969436 Test_accuracy: 0.942006\n",
      "990 Train accuracy: 0.935345 Test_accuracy: 0.905956\n",
      "1000 Train accuracy: 0.955721 Test_accuracy: 0.9279\n",
      "1010 Train accuracy: 0.951019 Test_accuracy: 0.935737\n",
      "1020 Train accuracy: 0.945533 Test_accuracy: 0.931035\n",
      "1030 Train accuracy: 0.951019 Test_accuracy: 0.918495\n",
      "1040 Train accuracy: 0.968652 Test_accuracy: 0.942006\n",
      "1050 Train accuracy: 0.96826 Test_accuracy: 0.949843\n",
      "1060 Train accuracy: 0.97453 Test_accuracy: 0.956113\n",
      "1070 Train accuracy: 0.969436 Test_accuracy: 0.946708\n",
      "1080 Train accuracy: 0.950627 Test_accuracy: 0.940439\n",
      "1090 Train accuracy: 0.960815 Test_accuracy: 0.940439\n",
      "1100 Train accuracy: 0.969828 Test_accuracy: 0.943574\n",
      "1110 Train accuracy: 0.969828 Test_accuracy: 0.945141\n",
      "1120 Train accuracy: 0.973746 Test_accuracy: 0.952978\n",
      "1130 Train accuracy: 0.960423 Test_accuracy: 0.935737\n",
      "1140 Train accuracy: 0.972571 Test_accuracy: 0.951411\n",
      "1150 Train accuracy: 0.976881 Test_accuracy: 0.951411\n",
      "1160 Train accuracy: 0.974138 Test_accuracy: 0.945141\n",
      "1170 Train accuracy: 0.958856 Test_accuracy: 0.932602\n",
      "1180 Train accuracy: 0.940831 Test_accuracy: 0.920063\n",
      "1190 Train accuracy: 0.961207 Test_accuracy: 0.937304\n",
      "1200 Train accuracy: 0.961599 Test_accuracy: 0.938872\n",
      "1210 Train accuracy: 0.969436 Test_accuracy: 0.946708\n",
      "1220 Train accuracy: 0.971003 Test_accuracy: 0.954545\n",
      "1230 Train accuracy: 0.96826 Test_accuracy: 0.938872\n",
      "1240 Train accuracy: 0.969044 Test_accuracy: 0.954545\n",
      "1250 Train accuracy: 0.962774 Test_accuracy: 0.937304\n",
      "1260 Train accuracy: 0.958464 Test_accuracy: 0.937304\n",
      "1270 Train accuracy: 0.967868 Test_accuracy: 0.946708\n",
      "1280 Train accuracy: 0.972962 Test_accuracy: 0.943574\n",
      "1290 Train accuracy: 0.975705 Test_accuracy: 0.952978\n",
      "1300 Train accuracy: 0.976097 Test_accuracy: 0.948276\n",
      "1310 Train accuracy: 0.978056 Test_accuracy: 0.954545\n",
      "1320 Train accuracy: 0.975313 Test_accuracy: 0.951411\n",
      "1330 Train accuracy: 0.970219 Test_accuracy: 0.95768\n",
      "1340 Train accuracy: 0.972962 Test_accuracy: 0.946708\n",
      "1350 Train accuracy: 0.964734 Test_accuracy: 0.943574\n",
      "1360 Train accuracy: 0.973746 Test_accuracy: 0.949843\n",
      "1370 Train accuracy: 0.976881 Test_accuracy: 0.948276\n",
      "1380 Train accuracy: 0.981191 Test_accuracy: 0.962382\n",
      "1390 Train accuracy: 0.980799 Test_accuracy: 0.956113\n",
      "1400 Train accuracy: 0.980016 Test_accuracy: 0.965517\n",
      "1410 Train accuracy: 0.959639 Test_accuracy: 0.942006\n",
      "1420 Train accuracy: 0.979624 Test_accuracy: 0.956113\n",
      "1430 Train accuracy: 0.981191 Test_accuracy: 0.956113\n",
      "1440 Train accuracy: 0.980799 Test_accuracy: 0.965517\n",
      "1450 Train accuracy: 0.973354 Test_accuracy: 0.945141\n",
      "1460 Train accuracy: 0.976097 Test_accuracy: 0.968652\n",
      "1470 Train accuracy: 0.974922 Test_accuracy: 0.96395\n",
      "1480 Train accuracy: 0.952194 Test_accuracy: 0.92163\n",
      "1490 Train accuracy: 0.965517 Test_accuracy: 0.935737\n",
      "1500 Train accuracy: 0.964342 Test_accuracy: 0.926332\n",
      "1510 Train accuracy: 0.979232 Test_accuracy: 0.960815\n",
      "1520 Train accuracy: 0.972962 Test_accuracy: 0.946708\n",
      "1530 Train accuracy: 0.971395 Test_accuracy: 0.951411\n",
      "1540 Train accuracy: 0.96826 Test_accuracy: 0.949843\n",
      "1550 Train accuracy: 0.980408 Test_accuracy: 0.945141\n",
      "1560 Train accuracy: 0.980408 Test_accuracy: 0.95768\n",
      "1570 Train accuracy: 0.982759 Test_accuracy: 0.962382\n",
      "1580 Train accuracy: 0.979232 Test_accuracy: 0.956113\n",
      "1590 Train accuracy: 0.977665 Test_accuracy: 0.949843\n",
      "1600 Train accuracy: 0.971003 Test_accuracy: 0.945141\n",
      "1610 Train accuracy: 0.961599 Test_accuracy: 0.943574\n",
      "1620 Train accuracy: 0.979624 Test_accuracy: 0.960815\n",
      "1630 Train accuracy: 0.952978 Test_accuracy: 0.915361\n",
      "1640 Train accuracy: 0.976489 Test_accuracy: 0.943574\n",
      "1650 Train accuracy: 0.979624 Test_accuracy: 0.946708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660 Train accuracy: 0.982759 Test_accuracy: 0.954545\n",
      "1670 Train accuracy: 0.974138 Test_accuracy: 0.951411\n",
      "1680 Train accuracy: 0.948276 Test_accuracy: 0.926332\n",
      "1690 Train accuracy: 0.976881 Test_accuracy: 0.952978\n",
      "1700 Train accuracy: 0.982367 Test_accuracy: 0.962382\n",
      "1710 Train accuracy: 0.981975 Test_accuracy: 0.959248\n",
      "1720 Train accuracy: 0.979232 Test_accuracy: 0.959248\n",
      "1730 Train accuracy: 0.983542 Test_accuracy: 0.954545\n",
      "1740 Train accuracy: 0.97453 Test_accuracy: 0.952978\n",
      "1750 Train accuracy: 0.978056 Test_accuracy: 0.95768\n",
      "1760 Train accuracy: 0.97884 Test_accuracy: 0.948276\n",
      "1770 Train accuracy: 0.981583 Test_accuracy: 0.959248\n",
      "1780 Train accuracy: 0.976881 Test_accuracy: 0.954545\n",
      "1790 Train accuracy: 0.981583 Test_accuracy: 0.951411\n",
      "1800 Train accuracy: 0.97884 Test_accuracy: 0.954545\n",
      "1810 Train accuracy: 0.98315 Test_accuracy: 0.95768\n",
      "1820 Train accuracy: 0.985893 Test_accuracy: 0.959248\n",
      "1830 Train accuracy: 0.98511 Test_accuracy: 0.960815\n",
      "1840 Train accuracy: 0.980408 Test_accuracy: 0.949843\n",
      "1850 Train accuracy: 0.978448 Test_accuracy: 0.949843\n",
      "1860 Train accuracy: 0.986677 Test_accuracy: 0.952978\n",
      "1870 Train accuracy: 0.977273 Test_accuracy: 0.951411\n",
      "1880 Train accuracy: 0.973746 Test_accuracy: 0.945141\n",
      "1890 Train accuracy: 0.941223 Test_accuracy: 0.918495\n",
      "1900 Train accuracy: 0.949843 Test_accuracy: 0.926332\n",
      "1910 Train accuracy: 0.946708 Test_accuracy: 0.931035\n",
      "1920 Train accuracy: 0.973746 Test_accuracy: 0.952978\n",
      "1930 Train accuracy: 0.975705 Test_accuracy: 0.951411\n",
      "1940 Train accuracy: 0.977273 Test_accuracy: 0.960815\n",
      "1950 Train accuracy: 0.981583 Test_accuracy: 0.959248\n",
      "1960 Train accuracy: 0.983934 Test_accuracy: 0.956113\n",
      "1970 Train accuracy: 0.985502 Test_accuracy: 0.95768\n",
      "1980 Train accuracy: 0.978448 Test_accuracy: 0.962382\n",
      "1990 Train accuracy: 0.984326 Test_accuracy: 0.960815\n",
      "2000 Train accuracy: 0.979624 Test_accuracy: 0.954545\n",
      "2010 Train accuracy: 0.981191 Test_accuracy: 0.952978\n",
      "2020 Train accuracy: 0.987069 Test_accuracy: 0.965517\n",
      "2030 Train accuracy: 0.983934 Test_accuracy: 0.959248\n",
      "2040 Train accuracy: 0.976097 Test_accuracy: 0.954545\n",
      "2050 Train accuracy: 0.983934 Test_accuracy: 0.960815\n",
      "2060 Train accuracy: 0.980408 Test_accuracy: 0.946708\n",
      "2070 Train accuracy: 0.985893 Test_accuracy: 0.949843\n",
      "2080 Train accuracy: 0.964342 Test_accuracy: 0.934169\n",
      "2090 Train accuracy: 0.954545 Test_accuracy: 0.920063\n",
      "2100 Train accuracy: 0.960031 Test_accuracy: 0.935737\n",
      "2110 Train accuracy: 0.978448 Test_accuracy: 0.960815\n",
      "2120 Train accuracy: 0.983542 Test_accuracy: 0.967085\n",
      "2130 Train accuracy: 0.976881 Test_accuracy: 0.943574\n",
      "2140 Train accuracy: 0.979232 Test_accuracy: 0.960815\n",
      "2150 Train accuracy: 0.972571 Test_accuracy: 0.937304\n",
      "2160 Train accuracy: 0.983934 Test_accuracy: 0.962382\n",
      "2170 Train accuracy: 0.968652 Test_accuracy: 0.946708\n",
      "2180 Train accuracy: 0.974138 Test_accuracy: 0.954545\n",
      "2190 Train accuracy: 0.980408 Test_accuracy: 0.942006\n",
      "2200 Train accuracy: 0.971003 Test_accuracy: 0.949843\n",
      "2210 Train accuracy: 0.980408 Test_accuracy: 0.948276\n",
      "2220 Train accuracy: 0.984718 Test_accuracy: 0.959248\n",
      "2230 Train accuracy: 0.984718 Test_accuracy: 0.956113\n",
      "2240 Train accuracy: 0.985502 Test_accuracy: 0.95768\n",
      "2250 Train accuracy: 0.985502 Test_accuracy: 0.960815\n",
      "2260 Train accuracy: 0.985893 Test_accuracy: 0.954545\n",
      "2270 Train accuracy: 0.987461 Test_accuracy: 0.962382\n",
      "2280 Train accuracy: 0.982759 Test_accuracy: 0.949843\n",
      "2290 Train accuracy: 0.988245 Test_accuracy: 0.95768\n",
      "2300 Train accuracy: 0.982367 Test_accuracy: 0.956113\n",
      "2310 Train accuracy: 0.984326 Test_accuracy: 0.948276\n",
      "2320 Train accuracy: 0.966693 Test_accuracy: 0.940439\n",
      "2330 Train accuracy: 0.984326 Test_accuracy: 0.95768\n",
      "2340 Train accuracy: 0.980799 Test_accuracy: 0.945141\n",
      "2350 Train accuracy: 0.984718 Test_accuracy: 0.95768\n",
      "2360 Train accuracy: 0.984718 Test_accuracy: 0.948276\n",
      "2370 Train accuracy: 0.986285 Test_accuracy: 0.96395\n",
      "2380 Train accuracy: 0.988636 Test_accuracy: 0.959248\n",
      "2390 Train accuracy: 0.981975 Test_accuracy: 0.951411\n",
      "2400 Train accuracy: 0.975705 Test_accuracy: 0.946708\n",
      "2410 Train accuracy: 0.980799 Test_accuracy: 0.938872\n",
      "2420 Train accuracy: 0.984718 Test_accuracy: 0.960815\n",
      "2430 Train accuracy: 0.984718 Test_accuracy: 0.954545\n",
      "2440 Train accuracy: 0.987853 Test_accuracy: 0.954545\n",
      "2450 Train accuracy: 0.98942 Test_accuracy: 0.96395\n",
      "2460 Train accuracy: 0.972179 Test_accuracy: 0.932602\n",
      "2470 Train accuracy: 0.987853 Test_accuracy: 0.960815\n",
      "2480 Train accuracy: 0.987069 Test_accuracy: 0.960815\n",
      "2490 Train accuracy: 0.988245 Test_accuracy: 0.962382\n",
      "2500 Train accuracy: 0.990596 Test_accuracy: 0.960815\n",
      "2510 Train accuracy: 0.978448 Test_accuracy: 0.940439\n",
      "2520 Train accuracy: 0.980799 Test_accuracy: 0.951411\n",
      "2530 Train accuracy: 0.984326 Test_accuracy: 0.960815\n",
      "2540 Train accuracy: 0.984718 Test_accuracy: 0.951411\n",
      "2550 Train accuracy: 0.986677 Test_accuracy: 0.95768\n",
      "2560 Train accuracy: 0.987461 Test_accuracy: 0.965517\n",
      "2570 Train accuracy: 0.988636 Test_accuracy: 0.949843\n",
      "2580 Train accuracy: 0.989028 Test_accuracy: 0.965517\n",
      "2590 Train accuracy: 0.946708 Test_accuracy: 0.912226\n",
      "2600 Train accuracy: 0.956897 Test_accuracy: 0.940439\n",
      "2610 Train accuracy: 0.972962 Test_accuracy: 0.952978\n",
      "2620 Train accuracy: 0.983934 Test_accuracy: 0.959248\n",
      "2630 Train accuracy: 0.980408 Test_accuracy: 0.95768\n",
      "2640 Train accuracy: 0.980799 Test_accuracy: 0.951411\n",
      "2650 Train accuracy: 0.980408 Test_accuracy: 0.959248\n",
      "2660 Train accuracy: 0.982367 Test_accuracy: 0.954545\n",
      "2670 Train accuracy: 0.975313 Test_accuracy: 0.938872\n",
      "2680 Train accuracy: 0.985502 Test_accuracy: 0.951411\n",
      "2690 Train accuracy: 0.984326 Test_accuracy: 0.960815\n",
      "2700 Train accuracy: 0.986285 Test_accuracy: 0.967085\n",
      "2710 Train accuracy: 0.986677 Test_accuracy: 0.971787\n",
      "2720 Train accuracy: 0.986677 Test_accuracy: 0.959248\n",
      "2730 Train accuracy: 0.978448 Test_accuracy: 0.959248\n",
      "2740 Train accuracy: 0.987853 Test_accuracy: 0.95768\n",
      "2750 Train accuracy: 0.983542 Test_accuracy: 0.952978\n",
      "2760 Train accuracy: 0.985502 Test_accuracy: 0.945141\n",
      "2770 Train accuracy: 0.967085 Test_accuracy: 0.935737\n",
      "2780 Train accuracy: 0.977273 Test_accuracy: 0.954545\n",
      "2790 Train accuracy: 0.980016 Test_accuracy: 0.943574\n",
      "2800 Train accuracy: 0.982367 Test_accuracy: 0.954545\n",
      "2810 Train accuracy: 0.991379 Test_accuracy: 0.954545\n",
      "2820 Train accuracy: 0.947492 Test_accuracy: 0.907524\n",
      "2830 Train accuracy: 0.956113 Test_accuracy: 0.940439\n",
      "2840 Train accuracy: 0.960815 Test_accuracy: 0.9279\n",
      "2850 Train accuracy: 0.975313 Test_accuracy: 0.951411\n",
      "2860 Train accuracy: 0.979624 Test_accuracy: 0.952978\n",
      "2870 Train accuracy: 0.987069 Test_accuracy: 0.95768\n",
      "2880 Train accuracy: 0.984326 Test_accuracy: 0.95768\n",
      "2890 Train accuracy: 0.989028 Test_accuracy: 0.962382\n",
      "2900 Train accuracy: 0.988245 Test_accuracy: 0.949843\n",
      "2910 Train accuracy: 0.988636 Test_accuracy: 0.96395\n",
      "2920 Train accuracy: 0.989028 Test_accuracy: 0.95768\n",
      "2930 Train accuracy: 0.97884 Test_accuracy: 0.942006\n",
      "2940 Train accuracy: 0.989812 Test_accuracy: 0.962382\n",
      "2950 Train accuracy: 0.992163 Test_accuracy: 0.962382\n",
      "2960 Train accuracy: 0.991771 Test_accuracy: 0.951411\n",
      "2970 Train accuracy: 0.992163 Test_accuracy: 0.960815\n",
      "2980 Train accuracy: 0.988636 Test_accuracy: 0.95768\n",
      "2990 Train accuracy: 0.990987 Test_accuracy: 0.96395\n",
      "Starting run for ./TMP/rnn,lr_1,rnn_node=150,fc_node=0,\n",
      "0 Train accuracy: 0.513323 Test_accuracy: 0.504702\n",
      "10 Train accuracy: 0.519984 Test_accuracy: 0.520376\n",
      "20 Train accuracy: 0.649295 Test_accuracy: 0.641066\n",
      "30 Train accuracy: 0.547806 Test_accuracy: 0.550157\n",
      "40 Train accuracy: 0.540752 Test_accuracy: 0.534483\n",
      "50 Train accuracy: 0.608542 Test_accuracy: 0.597179\n",
      "60 Train accuracy: 0.656348 Test_accuracy: 0.65047\n",
      "70 Train accuracy: 0.644984 Test_accuracy: 0.615987\n",
      "80 Train accuracy: 0.792712 Test_accuracy: 0.794671\n",
      "90 Train accuracy: 0.62931 Test_accuracy: 0.598746\n",
      "100 Train accuracy: 0.742947 Test_accuracy: 0.742947\n",
      "110 Train accuracy: 0.702194 Test_accuracy: 0.670846\n",
      "120 Train accuracy: 0.672806 Test_accuracy: 0.633229\n",
      "130 Train accuracy: 0.675157 Test_accuracy: 0.65047\n",
      "140 Train accuracy: 0.721787 Test_accuracy: 0.702194\n",
      "150 Train accuracy: 0.71826 Test_accuracy: 0.673981\n",
      "160 Train accuracy: 0.724922 Test_accuracy: 0.711599\n",
      "170 Train accuracy: 0.666536 Test_accuracy: 0.634796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 Train accuracy: 0.685737 Test_accuracy: 0.65047\n",
      "190 Train accuracy: 0.682994 Test_accuracy: 0.672414\n",
      "200 Train accuracy: 0.683386 Test_accuracy: 0.658307\n",
      "210 Train accuracy: 0.712382 Test_accuracy: 0.688088\n",
      "220 Train accuracy: 0.738636 Test_accuracy: 0.703762\n",
      "230 Train accuracy: 0.824843 Test_accuracy: 0.789969\n",
      "240 Train accuracy: 0.84953 Test_accuracy: 0.815047\n",
      "250 Train accuracy: 0.875784 Test_accuracy: 0.840125\n",
      "260 Train accuracy: 0.797414 Test_accuracy: 0.749216\n",
      "270 Train accuracy: 0.793495 Test_accuracy: 0.763323\n",
      "280 Train accuracy: 0.739028 Test_accuracy: 0.717868\n",
      "290 Train accuracy: 0.840909 Test_accuracy: 0.838558\n",
      "300 Train accuracy: 0.771944 Test_accuracy: 0.736677\n",
      "310 Train accuracy: 0.870298 Test_accuracy: 0.847962\n",
      "320 Train accuracy: 0.872649 Test_accuracy: 0.846395\n",
      "330 Train accuracy: 0.872257 Test_accuracy: 0.84953\n",
      "340 Train accuracy: 0.79232 Test_accuracy: 0.778997\n",
      "350 Train accuracy: 0.909091 Test_accuracy: 0.904389\n",
      "360 Train accuracy: 0.925549 Test_accuracy: 0.905956\n",
      "370 Train accuracy: 0.911834 Test_accuracy: 0.888715\n",
      "380 Train accuracy: 0.933777 Test_accuracy: 0.907524\n",
      "390 Train accuracy: 0.922022 Test_accuracy: 0.88558\n",
      "400 Train accuracy: 0.926724 Test_accuracy: 0.902821\n",
      "410 Train accuracy: 0.949843 Test_accuracy: 0.915361\n",
      "420 Train accuracy: 0.92594 Test_accuracy: 0.893417\n",
      "430 Train accuracy: 0.939263 Test_accuracy: 0.905956\n",
      "440 Train accuracy: 0.935737 Test_accuracy: 0.918495\n",
      "450 Train accuracy: 0.945533 Test_accuracy: 0.915361\n",
      "460 Train accuracy: 0.951802 Test_accuracy: 0.932602\n",
      "470 Train accuracy: 0.955721 Test_accuracy: 0.940439\n",
      "480 Train accuracy: 0.959248 Test_accuracy: 0.932602\n",
      "490 Train accuracy: 0.961207 Test_accuracy: 0.92163\n",
      "500 Train accuracy: 0.947884 Test_accuracy: 0.918495\n",
      "510 Train accuracy: 0.972571 Test_accuracy: 0.940439\n",
      "520 Train accuracy: 0.960815 Test_accuracy: 0.931035\n",
      "530 Train accuracy: 0.971395 Test_accuracy: 0.937304\n",
      "540 Train accuracy: 0.951802 Test_accuracy: 0.924765\n",
      "550 Train accuracy: 0.965517 Test_accuracy: 0.931035\n",
      "560 Train accuracy: 0.964342 Test_accuracy: 0.929467\n",
      "570 Train accuracy: 0.956113 Test_accuracy: 0.934169\n",
      "580 Train accuracy: 0.947492 Test_accuracy: 0.935737\n",
      "590 Train accuracy: 0.969044 Test_accuracy: 0.946708\n",
      "600 Train accuracy: 0.960031 Test_accuracy: 0.923198\n",
      "610 Train accuracy: 0.964342 Test_accuracy: 0.943574\n",
      "620 Train accuracy: 0.978448 Test_accuracy: 0.949843\n",
      "630 Train accuracy: 0.976097 Test_accuracy: 0.942006\n",
      "640 Train accuracy: 0.971003 Test_accuracy: 0.945141\n",
      "650 Train accuracy: 0.970611 Test_accuracy: 0.942006\n",
      "660 Train accuracy: 0.979624 Test_accuracy: 0.945141\n",
      "670 Train accuracy: 0.971395 Test_accuracy: 0.952978\n",
      "680 Train accuracy: 0.980016 Test_accuracy: 0.956113\n",
      "690 Train accuracy: 0.980408 Test_accuracy: 0.942006\n",
      "700 Train accuracy: 0.981975 Test_accuracy: 0.946708\n",
      "710 Train accuracy: 0.980016 Test_accuracy: 0.95768\n",
      "720 Train accuracy: 0.891066 Test_accuracy: 0.858934\n",
      "730 Train accuracy: 0.960815 Test_accuracy: 0.926332\n",
      "740 Train accuracy: 0.96395 Test_accuracy: 0.946708\n",
      "750 Train accuracy: 0.94279 Test_accuracy: 0.9279\n",
      "760 Train accuracy: 0.973354 Test_accuracy: 0.942006\n",
      "770 Train accuracy: 0.971787 Test_accuracy: 0.937304\n",
      "780 Train accuracy: 0.967868 Test_accuracy: 0.96395\n",
      "790 Train accuracy: 0.97884 Test_accuracy: 0.954545\n",
      "800 Train accuracy: 0.987461 Test_accuracy: 0.954545\n",
      "810 Train accuracy: 0.985502 Test_accuracy: 0.959248\n",
      "820 Train accuracy: 0.981975 Test_accuracy: 0.956113\n",
      "830 Train accuracy: 0.985502 Test_accuracy: 0.948276\n",
      "840 Train accuracy: 0.96395 Test_accuracy: 0.937304\n",
      "850 Train accuracy: 0.970219 Test_accuracy: 0.946708\n",
      "860 Train accuracy: 0.989812 Test_accuracy: 0.960815\n",
      "870 Train accuracy: 0.982367 Test_accuracy: 0.946708\n",
      "880 Train accuracy: 0.965909 Test_accuracy: 0.931035\n",
      "890 Train accuracy: 0.964342 Test_accuracy: 0.923198\n",
      "900 Train accuracy: 0.959248 Test_accuracy: 0.923198\n",
      "910 Train accuracy: 0.980016 Test_accuracy: 0.949843\n",
      "920 Train accuracy: 0.976097 Test_accuracy: 0.960815\n",
      "930 Train accuracy: 0.983934 Test_accuracy: 0.952978\n",
      "940 Train accuracy: 0.985893 Test_accuracy: 0.96395\n",
      "950 Train accuracy: 0.967868 Test_accuracy: 0.935737\n",
      "960 Train accuracy: 0.989028 Test_accuracy: 0.943574\n",
      "970 Train accuracy: 0.983542 Test_accuracy: 0.954545\n",
      "980 Train accuracy: 0.988636 Test_accuracy: 0.95768\n",
      "990 Train accuracy: 0.980799 Test_accuracy: 0.952978\n",
      "1000 Train accuracy: 0.992555 Test_accuracy: 0.960815\n",
      "1010 Train accuracy: 0.961207 Test_accuracy: 0.923198\n",
      "1020 Train accuracy: 0.97453 Test_accuracy: 0.945141\n",
      "1030 Train accuracy: 0.974922 Test_accuracy: 0.946708\n",
      "1040 Train accuracy: 0.983934 Test_accuracy: 0.95768\n",
      "1050 Train accuracy: 0.930251 Test_accuracy: 0.920063\n",
      "1060 Train accuracy: 0.972571 Test_accuracy: 0.945141\n",
      "1070 Train accuracy: 0.987853 Test_accuracy: 0.96395\n",
      "1080 Train accuracy: 0.983542 Test_accuracy: 0.934169\n",
      "1090 Train accuracy: 0.984718 Test_accuracy: 0.948276\n",
      "1100 Train accuracy: 0.98511 Test_accuracy: 0.956113\n",
      "1110 Train accuracy: 0.988245 Test_accuracy: 0.965517\n",
      "1120 Train accuracy: 0.987069 Test_accuracy: 0.960815\n",
      "1130 Train accuracy: 0.973354 Test_accuracy: 0.945141\n",
      "1140 Train accuracy: 0.98315 Test_accuracy: 0.954545\n",
      "1150 Train accuracy: 0.974138 Test_accuracy: 0.945141\n",
      "1160 Train accuracy: 0.987069 Test_accuracy: 0.952978\n",
      "1170 Train accuracy: 0.982759 Test_accuracy: 0.948276\n",
      "1180 Train accuracy: 0.952194 Test_accuracy: 0.92163\n",
      "1190 Train accuracy: 0.980408 Test_accuracy: 0.946708\n",
      "1200 Train accuracy: 0.976097 Test_accuracy: 0.949843\n",
      "1210 Train accuracy: 0.967476 Test_accuracy: 0.929467\n",
      "1220 Train accuracy: 0.98511 Test_accuracy: 0.95768\n",
      "1230 Train accuracy: 0.987069 Test_accuracy: 0.95768\n",
      "1240 Train accuracy: 0.991379 Test_accuracy: 0.954545\n",
      "1250 Train accuracy: 0.990204 Test_accuracy: 0.95768\n",
      "1260 Train accuracy: 0.977665 Test_accuracy: 0.956113\n",
      "1270 Train accuracy: 0.966693 Test_accuracy: 0.938872\n",
      "1280 Train accuracy: 0.982759 Test_accuracy: 0.946708\n",
      "1290 Train accuracy: 0.988245 Test_accuracy: 0.943574\n",
      "1300 Train accuracy: 0.989028 Test_accuracy: 0.943574\n",
      "1310 Train accuracy: 0.990987 Test_accuracy: 0.968652\n",
      "1320 Train accuracy: 0.993339 Test_accuracy: 0.95768\n",
      "1330 Train accuracy: 0.992163 Test_accuracy: 0.95768\n",
      "1340 Train accuracy: 0.992947 Test_accuracy: 0.95768\n",
      "1350 Train accuracy: 0.988636 Test_accuracy: 0.959248\n",
      "1360 Train accuracy: 0.990204 Test_accuracy: 0.952978\n",
      "1370 Train accuracy: 0.991379 Test_accuracy: 0.962382\n",
      "1380 Train accuracy: 0.992947 Test_accuracy: 0.95768\n",
      "1390 Train accuracy: 0.99373 Test_accuracy: 0.965517\n",
      "1400 Train accuracy: 0.992163 Test_accuracy: 0.95768\n",
      "1410 Train accuracy: 0.994122 Test_accuracy: 0.96395\n",
      "1420 Train accuracy: 0.997257 Test_accuracy: 0.965517\n",
      "1430 Train accuracy: 0.99373 Test_accuracy: 0.949843\n",
      "1440 Train accuracy: 0.997257 Test_accuracy: 0.956113\n",
      "1450 Train accuracy: 0.99569 Test_accuracy: 0.95768\n",
      "1460 Train accuracy: 0.993339 Test_accuracy: 0.960815\n",
      "1470 Train accuracy: 0.993339 Test_accuracy: 0.95768\n",
      "1480 Train accuracy: 0.997257 Test_accuracy: 0.954545\n",
      "1490 Train accuracy: 0.997257 Test_accuracy: 0.959248\n",
      "1500 Train accuracy: 0.997649 Test_accuracy: 0.959248\n",
      "1510 Train accuracy: 0.977273 Test_accuracy: 0.938872\n",
      "1520 Train accuracy: 0.974138 Test_accuracy: 0.952978\n",
      "1530 Train accuracy: 0.979624 Test_accuracy: 0.929467\n",
      "1540 Train accuracy: 0.986285 Test_accuracy: 0.940439\n",
      "1550 Train accuracy: 0.980799 Test_accuracy: 0.934169\n",
      "1560 Train accuracy: 0.976489 Test_accuracy: 0.929467\n",
      "1570 Train accuracy: 0.992163 Test_accuracy: 0.956113\n",
      "1580 Train accuracy: 0.990204 Test_accuracy: 0.951411\n",
      "1590 Train accuracy: 0.992555 Test_accuracy: 0.949843\n",
      "1600 Train accuracy: 0.99373 Test_accuracy: 0.959248\n",
      "1610 Train accuracy: 0.994906 Test_accuracy: 0.959248\n",
      "1620 Train accuracy: 0.996473 Test_accuracy: 0.951411\n",
      "1630 Train accuracy: 0.991379 Test_accuracy: 0.951411\n",
      "1640 Train accuracy: 0.991771 Test_accuracy: 0.945141\n",
      "1650 Train accuracy: 0.991379 Test_accuracy: 0.954545\n",
      "1660 Train accuracy: 0.988636 Test_accuracy: 0.951411\n",
      "1670 Train accuracy: 0.988636 Test_accuracy: 0.956113\n",
      "1680 Train accuracy: 0.986285 Test_accuracy: 0.946708\n",
      "1690 Train accuracy: 0.992947 Test_accuracy: 0.95768\n",
      "1700 Train accuracy: 0.98315 Test_accuracy: 0.951411\n",
      "1710 Train accuracy: 0.994122 Test_accuracy: 0.954545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720 Train accuracy: 0.980799 Test_accuracy: 0.940439\n",
      "1730 Train accuracy: 0.981583 Test_accuracy: 0.932602\n",
      "1740 Train accuracy: 0.991771 Test_accuracy: 0.95768\n",
      "1750 Train accuracy: 0.971787 Test_accuracy: 0.923198\n",
      "1760 Train accuracy: 0.987069 Test_accuracy: 0.952978\n",
      "1770 Train accuracy: 0.990204 Test_accuracy: 0.948276\n",
      "1780 Train accuracy: 0.991771 Test_accuracy: 0.956113\n",
      "1790 Train accuracy: 0.937696 Test_accuracy: 0.9279\n",
      "1800 Train accuracy: 0.967476 Test_accuracy: 0.929467\n",
      "1810 Train accuracy: 0.981191 Test_accuracy: 0.954545\n",
      "1820 Train accuracy: 0.978448 Test_accuracy: 0.946708\n",
      "1830 Train accuracy: 0.992555 Test_accuracy: 0.956113\n",
      "1840 Train accuracy: 0.970219 Test_accuracy: 0.931035\n",
      "1850 Train accuracy: 0.983542 Test_accuracy: 0.931035\n",
      "1860 Train accuracy: 0.984326 Test_accuracy: 0.95768\n",
      "1870 Train accuracy: 0.98511 Test_accuracy: 0.940439\n",
      "1880 Train accuracy: 0.987461 Test_accuracy: 0.954545\n",
      "1890 Train accuracy: 0.980016 Test_accuracy: 0.942006\n",
      "1900 Train accuracy: 0.989028 Test_accuracy: 0.954545\n",
      "1910 Train accuracy: 0.987461 Test_accuracy: 0.938872\n",
      "1920 Train accuracy: 0.994514 Test_accuracy: 0.949843\n",
      "1930 Train accuracy: 0.992555 Test_accuracy: 0.959248\n",
      "1940 Train accuracy: 0.995298 Test_accuracy: 0.95768\n",
      "1950 Train accuracy: 0.995298 Test_accuracy: 0.954545\n",
      "1960 Train accuracy: 0.990204 Test_accuracy: 0.951411\n",
      "1970 Train accuracy: 0.994122 Test_accuracy: 0.954545\n",
      "1980 Train accuracy: 0.996473 Test_accuracy: 0.954545\n",
      "1990 Train accuracy: 0.993339 Test_accuracy: 0.942006\n",
      "2000 Train accuracy: 0.987069 Test_accuracy: 0.9279\n",
      "2010 Train accuracy: 0.993339 Test_accuracy: 0.952978\n",
      "2020 Train accuracy: 0.997257 Test_accuracy: 0.951411\n",
      "2030 Train accuracy: 0.997649 Test_accuracy: 0.952978\n",
      "2040 Train accuracy: 0.99569 Test_accuracy: 0.954545\n",
      "2050 Train accuracy: 0.99569 Test_accuracy: 0.954545\n",
      "2060 Train accuracy: 0.997649 Test_accuracy: 0.956113\n",
      "2070 Train accuracy: 0.997257 Test_accuracy: 0.95768\n",
      "2080 Train accuracy: 0.997649 Test_accuracy: 0.952978\n",
      "2090 Train accuracy: 0.998433 Test_accuracy: 0.952978\n",
      "2100 Train accuracy: 0.996473 Test_accuracy: 0.956113\n",
      "2110 Train accuracy: 0.995298 Test_accuracy: 0.954545\n",
      "2120 Train accuracy: 0.998824 Test_accuracy: 0.95768\n",
      "2130 Train accuracy: 0.998824 Test_accuracy: 0.954545\n",
      "2140 Train accuracy: 0.992947 Test_accuracy: 0.948276\n",
      "2150 Train accuracy: 0.997649 Test_accuracy: 0.951411\n",
      "2160 Train accuracy: 0.998824 Test_accuracy: 0.956113\n",
      "2170 Train accuracy: 0.998824 Test_accuracy: 0.956113\n",
      "2180 Train accuracy: 0.998041 Test_accuracy: 0.945141\n",
      "2190 Train accuracy: 0.998824 Test_accuracy: 0.95768\n",
      "2200 Train accuracy: 0.998824 Test_accuracy: 0.956113\n",
      "2210 Train accuracy: 0.998824 Test_accuracy: 0.956113\n",
      "2220 Train accuracy: 0.997649 Test_accuracy: 0.95768\n",
      "2230 Train accuracy: 0.998824 Test_accuracy: 0.959248\n",
      "2240 Train accuracy: 0.998433 Test_accuracy: 0.959248\n",
      "2250 Train accuracy: 0.998824 Test_accuracy: 0.960815\n",
      "2260 Train accuracy: 0.998433 Test_accuracy: 0.960815\n",
      "2270 Train accuracy: 0.998433 Test_accuracy: 0.962382\n",
      "2280 Train accuracy: 0.998824 Test_accuracy: 0.959248\n",
      "2290 Train accuracy: 0.998824 Test_accuracy: 0.959248\n",
      "2300 Train accuracy: 0.992163 Test_accuracy: 0.935737\n",
      "2310 Train accuracy: 0.996082 Test_accuracy: 0.956113\n",
      "2320 Train accuracy: 0.975705 Test_accuracy: 0.9279\n",
      "2330 Train accuracy: 0.947492 Test_accuracy: 0.902821\n",
      "2340 Train accuracy: 0.905172 Test_accuracy: 0.87931\n",
      "2350 Train accuracy: 0.944357 Test_accuracy: 0.904389\n",
      "2360 Train accuracy: 0.970219 Test_accuracy: 0.949843\n",
      "2370 Train accuracy: 0.976881 Test_accuracy: 0.956113\n",
      "2380 Train accuracy: 0.977273 Test_accuracy: 0.952978\n",
      "2390 Train accuracy: 0.972962 Test_accuracy: 0.954545\n",
      "2400 Train accuracy: 0.987461 Test_accuracy: 0.956113\n",
      "2410 Train accuracy: 0.981975 Test_accuracy: 0.956113\n",
      "2420 Train accuracy: 0.981975 Test_accuracy: 0.945141\n",
      "2430 Train accuracy: 0.98315 Test_accuracy: 0.951411\n",
      "2440 Train accuracy: 0.992163 Test_accuracy: 0.954545\n",
      "2450 Train accuracy: 0.99373 Test_accuracy: 0.954545\n",
      "2460 Train accuracy: 0.993339 Test_accuracy: 0.951411\n",
      "2470 Train accuracy: 0.994514 Test_accuracy: 0.95768\n",
      "2480 Train accuracy: 0.987853 Test_accuracy: 0.951411\n",
      "2490 Train accuracy: 0.994514 Test_accuracy: 0.954545\n",
      "2500 Train accuracy: 0.99569 Test_accuracy: 0.956113\n",
      "2510 Train accuracy: 0.996865 Test_accuracy: 0.962382\n",
      "2520 Train accuracy: 0.997649 Test_accuracy: 0.951411\n",
      "2530 Train accuracy: 0.99569 Test_accuracy: 0.942006\n",
      "2540 Train accuracy: 0.992555 Test_accuracy: 0.931035\n",
      "2550 Train accuracy: 0.990204 Test_accuracy: 0.945141\n",
      "2560 Train accuracy: 0.984326 Test_accuracy: 0.945141\n",
      "2570 Train accuracy: 0.991379 Test_accuracy: 0.949843\n",
      "2580 Train accuracy: 0.97884 Test_accuracy: 0.946708\n",
      "2590 Train accuracy: 0.988245 Test_accuracy: 0.948276\n",
      "2600 Train accuracy: 0.95768 Test_accuracy: 0.929467\n",
      "2610 Train accuracy: 0.979624 Test_accuracy: 0.942006\n",
      "2620 Train accuracy: 0.985502 Test_accuracy: 0.951411\n",
      "2630 Train accuracy: 0.989028 Test_accuracy: 0.956113\n",
      "2640 Train accuracy: 0.988636 Test_accuracy: 0.949843\n",
      "2650 Train accuracy: 0.963558 Test_accuracy: 0.913793\n",
      "2660 Train accuracy: 0.986677 Test_accuracy: 0.946708\n",
      "2670 Train accuracy: 0.98315 Test_accuracy: 0.952978\n",
      "2680 Train accuracy: 0.994514 Test_accuracy: 0.954545\n",
      "2690 Train accuracy: 0.994122 Test_accuracy: 0.951411\n",
      "2700 Train accuracy: 0.991379 Test_accuracy: 0.959248\n",
      "2710 Train accuracy: 0.992555 Test_accuracy: 0.956113\n",
      "2720 Train accuracy: 0.986285 Test_accuracy: 0.946708\n",
      "2730 Train accuracy: 0.996082 Test_accuracy: 0.954545\n",
      "2740 Train accuracy: 0.996865 Test_accuracy: 0.938872\n",
      "2750 Train accuracy: 0.998433 Test_accuracy: 0.952978\n",
      "2760 Train accuracy: 0.998433 Test_accuracy: 0.956113\n",
      "2770 Train accuracy: 0.998824 Test_accuracy: 0.960815\n",
      "2780 Train accuracy: 0.998824 Test_accuracy: 0.954545\n",
      "2790 Train accuracy: 0.998824 Test_accuracy: 0.960815\n",
      "2800 Train accuracy: 0.998824 Test_accuracy: 0.95768\n",
      "2810 Train accuracy: 0.998824 Test_accuracy: 0.956113\n",
      "2820 Train accuracy: 0.998824 Test_accuracy: 0.965517\n",
      "2830 Train accuracy: 0.998824 Test_accuracy: 0.967085\n",
      "2840 Train accuracy: 0.998824 Test_accuracy: 0.959248\n",
      "2850 Train accuracy: 0.998824 Test_accuracy: 0.965517\n",
      "2860 Train accuracy: 0.998824 Test_accuracy: 0.965517\n",
      "2870 Train accuracy: 0.998824 Test_accuracy: 0.965517\n",
      "2880 Train accuracy: 0.999216 Test_accuracy: 0.962382\n",
      "2890 Train accuracy: 0.999216 Test_accuracy: 0.965517\n",
      "2900 Train accuracy: 0.998824 Test_accuracy: 0.965517\n",
      "2910 Train accuracy: 0.998824 Test_accuracy: 0.96395\n",
      "2920 Train accuracy: 0.998824 Test_accuracy: 0.967085\n",
      "2930 Train accuracy: 0.998824 Test_accuracy: 0.96395\n",
      "2940 Train accuracy: 0.998824 Test_accuracy: 0.96395\n",
      "2950 Train accuracy: 0.999216 Test_accuracy: 0.960815\n",
      "2960 Train accuracy: 0.999216 Test_accuracy: 0.965517\n",
      "2970 Train accuracy: 0.999216 Test_accuracy: 0.96395\n",
      "2980 Train accuracy: 0.999216 Test_accuracy: 0.962382\n",
      "2990 Train accuracy: 0.999216 Test_accuracy: 0.960815\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qli45\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
